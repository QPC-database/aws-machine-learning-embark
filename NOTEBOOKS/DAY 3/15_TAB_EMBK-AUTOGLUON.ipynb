{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoGluon\n",
    "\n",
    "In this notebook, we use __AutoGluon__ to predict the __Outcome Type__ field of our review dataset.\n",
    "\n",
    "1. <a href=\"#1\">Set up AutoGluon</a>\n",
    "2. <a href=\"#2\">Read the datasets</a>\n",
    "3. <a href=\"#3\">Train a classifier with AutoGluon</a>\n",
    "4. <a href=\"#4\">Model evaluation</a>\n",
    "5. <a href=\"#5\">Clean up model artifacts</a>\n",
    "\n",
    "__Austin Animal Center Dataset__:\n",
    "\n",
    "In this exercise, we are working with pet adoption data from __Austin Animal Center__. We have two datasets that cover intake and outcome of animals. Intake data is available from [here](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm) and outcome is from [here](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238). \n",
    "\n",
    "In order to work with a single table, we joined the intake and outcome tables using the \"Animal ID\" column and created a single __review.csv__ file. We also didn't consider animals with multiple entries to the facility to keep our dataset simple. If you want to see the original datasets and the merged data with multiple entries, they are available under `DATA/review` folder: Austin_Animal_Center_Intakes.csv, Austin_Animal_Center_Outcomes.csv and Austin_Animal_Center_Intakes_Outcomes.csv.\n",
    "\n",
    "__Dataset schema:__ \n",
    "- __Pet ID__ - Unique ID of pet\n",
    "- __Outcome Type__ - State of pet at the time of recording the outcome (0 = not placed, 1 = placed). This is the field to predict.\n",
    "- __Sex upon Outcome__ - Sex of pet at outcome\n",
    "- __Name__ - Name of pet \n",
    "- __Found Location__ - Found location of pet before entered the center\n",
    "- __Intake Type__ - Circumstances bringing the pet to the center\n",
    "- __Intake Condition__ - Health condition of pet when entered the center\n",
    "- __Pet Type__ - Type of pet\n",
    "- __Sex upon Intake__ - Sex of pet when entered the center\n",
    "- __Breed__ - Breed of pet \n",
    "- __Color__ - Color of pet \n",
    "- __Age upon Intake Days__ - Age of pet when entered the center (days)\n",
    "- __Age upon Outcome Days__ - Age of pet at outcome (days)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Set up AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[AutoGluon](https://autogluon.mxnet.io/tutorials/tabular_prediction/index.html) implements many of the best practices that we have discussed in this class, and more!  In particular, it sets itself apart from other AutoML solutions by having excellent automated feature engineering that can handle text data and missing values without any hand-coded solutions (see their [paper](https://arxiv.org/abs/2003.06505) for details).  It is too new to be in an existing Sagemaker kernel, so let's install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --upgrade pip\n",
    "# !pip install --upgrade mxnet autogluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "if not sys.warnoptions:\n",
    "    import warnings\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Read the dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's read the dataset into a dataframe, using Pandas, and split the dataset into train and test sets (AutoGluon will handle the validation itself)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('../../DATA/review/review_dataset.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.1, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Train a classifier with AutoGluon</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We can run AutoGluon with a short snippet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No path specified. Models will be saved in: \"AutogluonModels/ag-20210630_211347/\"\n",
      "Beginning AutoGluon training ...\n",
      "AutoGluon will save models to \"AutogluonModels/ag-20210630_211347/\"\n",
      "AutoGluon Version:  0.2.0\n",
      "Train Data Rows:    1000\n",
      "Train Data Columns: 12\n",
      "Preprocessing data ...\n",
      "AutoGluon infers your prediction problem is: 'binary' (because only two unique label-values observed).\n",
      "\t2 unique label values:  [1.0, 0.0]\n",
      "\tIf 'binary' is not the correct problem_type, please manually specify the problem_type argument in fit() (You may specify problem_type as one of: ['binary', 'multiclass', 'regression'])\n",
      "Selected class <--> label mapping:  class 1 = 1, class 0 = 0\n",
      "Using Feature Generators to preprocess the data ...\n",
      "Fitting AutoMLPipelineFeatureGenerator...\n",
      "\tAvailable Memory:                    58531.39 MB\n",
      "\tTrain Data (Original)  Memory Usage: 0.69 MB (0.0% of available memory)\n",
      "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
      "\tStage 1 Generators:\n",
      "\t\tFitting AsTypeFeatureGenerator...\n",
      "\tStage 2 Generators:\n",
      "\t\tFitting FillNaFeatureGenerator...\n",
      "\tStage 3 Generators:\n",
      "\t\tFitting IdentityFeatureGenerator...\n",
      "\t\tFitting CategoryFeatureGenerator...\n",
      "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
      "\t\tFitting TextSpecialFeatureGenerator...\n",
      "\t\t\tFitting BinnedFeatureGenerator...\n",
      "\t\t\tFitting DropDuplicatesFeatureGenerator...\n",
      "\t\tFitting TextNgramFeatureGenerator...\n",
      "\t\t\tFitting CountVectorizer for text features: ['Found Location']\n",
      "\t\t\tCountVectorizer fit with vocabulary size = 31\n",
      "\tStage 4 Generators:\n",
      "\t\tFitting DropUniqueFeatureGenerator...\n",
      "\tUnused Original Features (Count: 1): ['Pet ID']\n",
      "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
      "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
      "\t\tThese features do not need to be present at inference time.\n",
      "\t\t('object', []) : 1 | ['Pet ID']\n",
      "\tTypes of features in original data (raw dtype, special dtypes):\n",
      "\t\t('int', [])          : 2 | ['Age upon Intake Days', 'Age upon Outcome Days']\n",
      "\t\t('object', [])       : 8 | ['Sex upon Outcome', 'Name', 'Intake Type', 'Intake Condition', 'Pet Type', ...]\n",
      "\t\t('object', ['text']) : 1 | ['Found Location']\n",
      "\tTypes of features in processed data (raw dtype, special dtypes):\n",
      "\t\t('category', [])                    :  8 | ['Sex upon Outcome', 'Name', 'Intake Type', 'Intake Condition', 'Pet Type', ...]\n",
      "\t\t('category', ['text_as_category'])  :  1 | ['Found Location']\n",
      "\t\t('int', [])                         :  2 | ['Age upon Intake Days', 'Age upon Outcome Days']\n",
      "\t\t('int', ['binned', 'text_special']) : 19 | ['Found Location.char_count', 'Found Location.word_count', 'Found Location.capital_ratio', 'Found Location.lower_ratio', 'Found Location.digit_ratio', ...]\n",
      "\t\t('int', ['text_ngram'])             : 32 | ['__nlp__.and', '__nlp__.austin', '__nlp__.austin tx', '__nlp__.dr', '__nlp__.dr in', ...]\n",
      "\t1.1s = Fit runtime\n",
      "\t11 features in original data used to generate 62 features in processed data.\n",
      "\tTrain Data (Processed) Memory Usage: 0.1 MB (0.0% of available memory)\n",
      "Data preprocessing and feature engineering runtime = 1.13s ...\n",
      "AutoGluon will gauge predictive performance using evaluation metric: 'f1'\n",
      "\tTo change this, specify the eval_metric argument of fit()\n",
      "Automatically generating train/validation split with holdout_frac=0.2, Train Rows: 800, Val Rows: 200\n",
      "Fitting model: KNeighborsUnif ...\n",
      "\t0.6746\t = Validation f1 score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: KNeighborsDist ...\n",
      "\t0.6824\t = Validation f1 score\n",
      "\t0.0s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: LightGBMXT ...\n",
      "\t0.8559\t = Validation f1 score\n",
      "\t1.74s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: LightGBM ...\n",
      "\t0.8407\t = Validation f1 score\n",
      "\t2.93s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: RandomForestGini ...\n",
      "\t0.8523\t = Validation f1 score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: RandomForestEntr ...\n",
      "\t0.8523\t = Validation f1 score\n",
      "\t0.86s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: CatBoost ...\n",
      "\t0.8658\t = Validation f1 score\n",
      "\t0.83s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: ExtraTreesGini ...\n",
      "\t0.8487\t = Validation f1 score\n",
      "\t0.96s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: ExtraTreesEntr ...\n",
      "\t0.8596\t = Validation f1 score\n",
      "\t0.96s\t = Training runtime\n",
      "\t0.11s\t = Validation runtime\n",
      "Fitting model: NeuralNetFastAI ...\n",
      "No improvement since epoch 8: early stopping\n",
      "\t0.8066\t = Validation f1 score\n",
      "\t1.82s\t = Training runtime\n",
      "\t0.06s\t = Validation runtime\n",
      "Fitting model: XGBoost ...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[21:14:00] WARNING: ../src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\t0.839\t = Validation f1 score\n",
      "\t1.32s\t = Training runtime\n",
      "\t0.01s\t = Validation runtime\n",
      "Fitting model: NeuralNetMXNet ...\n",
      "\t0.8106\t = Validation f1 score\n",
      "\t15.23s\t = Training runtime\n",
      "\t0.24s\t = Validation runtime\n",
      "Fitting model: LightGBMLarge ...\n",
      "\t0.8353\t = Validation f1 score\n",
      "\t1.3s\t = Training runtime\n",
      "\t0.02s\t = Validation runtime\n",
      "Fitting model: WeightedEnsemble_L2 ...\n",
      "\t0.8755\t = Validation f1 score\n",
      "\t1.71s\t = Training runtime\n",
      "\t0.0s\t = Validation runtime\n",
      "AutoGluon training complete, total runtime = 33.99s ...\n",
      "TabularPredictor saved. To load, use: predictor = TabularPredictor.load(\"AutogluonModels/ag-20210630_211347/\")\n"
     ]
    }
   ],
   "source": [
    "from autogluon.tabular import TabularPredictor\n",
    "\n",
    "k = 1000 # grab less data for a quick demo\n",
    "#k = train_data.shape[0] # grad the whole dataset; \n",
    "\n",
    "predictor = TabularPredictor(label='Outcome Type', eval_metric = 'f1').fit(train_data=train_data.sample(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Model evaluation</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n",
      "Evaluation: f1 on test data: 0.8520463600144874\n",
      "Evaluations on test data:\n",
      "{\n",
      "    \"f1\": 0.8520463600144874,\n",
      "    \"accuracy\": 0.8288826055084302,\n",
      "    \"balanced_accuracy\": 0.8227127195032097,\n",
      "    \"mcc\": 0.650000066092912,\n",
      "    \"precision\": 0.8361471476808245,\n",
      "    \"recall\": 0.8685619346501754\n",
      "}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'f1': 0.8520463600144874,\n",
       " 'accuracy': 0.8288826055084302,\n",
       " 'balanced_accuracy': 0.8227127195032097,\n",
       " 'mcc': 0.650000066092912,\n",
       " 'precision': 0.8361471476808245,\n",
       " 'recall': 0.8685619346501754}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predictor.predict(test_data)\n",
    "predictor.evaluate_predictions(y_true=test_data['Outcome Type'], y_pred=y_pred, auxiliary_metrics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>score_val</th>\n",
       "      <th>pred_time_val</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>pred_time_val_marginal</th>\n",
       "      <th>fit_time_marginal</th>\n",
       "      <th>stack_level</th>\n",
       "      <th>can_infer</th>\n",
       "      <th>fit_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>WeightedEnsemble_L2</td>\n",
       "      <td>0.875536</td>\n",
       "      <td>0.268644</td>\n",
       "      <td>7.285246</td>\n",
       "      <td>0.001821</td>\n",
       "      <td>1.713055</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CatBoost</td>\n",
       "      <td>0.865801</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.825659</td>\n",
       "      <td>0.021074</td>\n",
       "      <td>0.825659</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ExtraTreesEntr</td>\n",
       "      <td>0.859574</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.959247</td>\n",
       "      <td>0.113189</td>\n",
       "      <td>0.959247</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LightGBMXT</td>\n",
       "      <td>0.855895</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>1.735614</td>\n",
       "      <td>0.019708</td>\n",
       "      <td>1.735614</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestGini</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.112877</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>0.112877</td>\n",
       "      <td>0.858639</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestEntr</td>\n",
       "      <td>0.852321</td>\n",
       "      <td>0.112895</td>\n",
       "      <td>0.856853</td>\n",
       "      <td>0.112895</td>\n",
       "      <td>0.856853</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesGini</td>\n",
       "      <td>0.848739</td>\n",
       "      <td>0.112864</td>\n",
       "      <td>0.959635</td>\n",
       "      <td>0.112864</td>\n",
       "      <td>0.959635</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LightGBM</td>\n",
       "      <td>0.840708</td>\n",
       "      <td>0.019666</td>\n",
       "      <td>2.930432</td>\n",
       "      <td>0.019666</td>\n",
       "      <td>2.930432</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>0.838983</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>1.319662</td>\n",
       "      <td>0.012448</td>\n",
       "      <td>1.319662</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LightGBMLarge</td>\n",
       "      <td>0.835341</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>1.304277</td>\n",
       "      <td>0.019737</td>\n",
       "      <td>1.304277</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NeuralNetMXNet</td>\n",
       "      <td>0.810573</td>\n",
       "      <td>0.238151</td>\n",
       "      <td>15.231140</td>\n",
       "      <td>0.238151</td>\n",
       "      <td>15.231140</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NeuralNetFastAI</td>\n",
       "      <td>0.806584</td>\n",
       "      <td>0.064175</td>\n",
       "      <td>1.823059</td>\n",
       "      <td>0.064175</td>\n",
       "      <td>1.823059</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>KNeighborsDist</td>\n",
       "      <td>0.682353</td>\n",
       "      <td>0.105240</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>0.105240</td>\n",
       "      <td>0.003062</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>KNeighborsUnif</td>\n",
       "      <td>0.674603</td>\n",
       "      <td>0.105095</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>0.105095</td>\n",
       "      <td>0.003554</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  model  score_val  pred_time_val   fit_time  \\\n",
       "0   WeightedEnsemble_L2   0.875536       0.268644   7.285246   \n",
       "1              CatBoost   0.865801       0.021074   0.825659   \n",
       "2        ExtraTreesEntr   0.859574       0.113189   0.959247   \n",
       "3            LightGBMXT   0.855895       0.019708   1.735614   \n",
       "4      RandomForestGini   0.852321       0.112877   0.858639   \n",
       "5      RandomForestEntr   0.852321       0.112895   0.856853   \n",
       "6        ExtraTreesGini   0.848739       0.112864   0.959635   \n",
       "7              LightGBM   0.840708       0.019666   2.930432   \n",
       "8               XGBoost   0.838983       0.012448   1.319662   \n",
       "9         LightGBMLarge   0.835341       0.019737   1.304277   \n",
       "10       NeuralNetMXNet   0.810573       0.238151  15.231140   \n",
       "11      NeuralNetFastAI   0.806584       0.064175   1.823059   \n",
       "12       KNeighborsDist   0.682353       0.105240   0.003062   \n",
       "13       KNeighborsUnif   0.674603       0.105095   0.003554   \n",
       "\n",
       "    pred_time_val_marginal  fit_time_marginal  stack_level  can_infer  \\\n",
       "0                 0.001821           1.713055            2       True   \n",
       "1                 0.021074           0.825659            1       True   \n",
       "2                 0.113189           0.959247            1       True   \n",
       "3                 0.019708           1.735614            1       True   \n",
       "4                 0.112877           0.858639            1       True   \n",
       "5                 0.112895           0.856853            1       True   \n",
       "6                 0.112864           0.959635            1       True   \n",
       "7                 0.019666           2.930432            1       True   \n",
       "8                 0.012448           1.319662            1       True   \n",
       "9                 0.019737           1.304277            1       True   \n",
       "10                0.238151          15.231140            1       True   \n",
       "11                0.064175           1.823059            1       True   \n",
       "12                0.105240           0.003062            1       True   \n",
       "13                0.105095           0.003554            1       True   \n",
       "\n",
       "    fit_order  \n",
       "0          14  \n",
       "1           7  \n",
       "2           9  \n",
       "3           3  \n",
       "4           5  \n",
       "5           6  \n",
       "6           8  \n",
       "7           4  \n",
       "8          11  \n",
       "9          13  \n",
       "10         12  \n",
       "11         10  \n",
       "12          2  \n",
       "13          1  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictor.leaderboard(silent=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Clean up model artifacts</a>\n",
    "(<a href=\"#0\">Go to top</a>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/mxnet_latest_p37/lib/python3.7/site-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "!rm -r AutogluonModels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_latest_p37",
   "language": "python",
   "name": "conda_mxnet_latest_p37"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
