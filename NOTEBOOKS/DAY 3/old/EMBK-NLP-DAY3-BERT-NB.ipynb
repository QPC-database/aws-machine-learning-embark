{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding with BERT using GluonNLP\n",
    "\n",
    "This notebook provides a short example of installing GluonNLP, and then using a pretrained BERT model to encode a sentence.  This can be used as an encoding method for any other downstream learning algorithm, and is an excellent method to use during early stages of product development.  If the application seems sound, the model can be fine-tuned for additional performance.  Scripts to aid in this task can be found [here](https://gluon-nlp.mxnet.io/master/model_zoo/bert/index.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (20.0.2)\n",
      "Requirement already up-to-date: mxnet in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (1.5.1.post0)\n",
      "Requirement already up-to-date: gluonnlp in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.8.3)\n",
      "Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet) (1.16.4)\n",
      "Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet) (2.20.0)\n",
      "Requirement already satisfied, skipping upgrade: graphviz<0.9.0,>=0.8.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from mxnet) (0.8.4)\n",
      "Requirement already satisfied, skipping upgrade: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (1.23)\n",
      "Requirement already satisfied, skipping upgrade: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2.6)\n",
      "Requirement already satisfied, skipping upgrade: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n",
      "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from requests<3,>=2.20.0->mxnet) (2019.9.11)\n"
     ]
    }
   ],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "# Load Relevant Libraries\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade mxnet gluonnlp\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gluonnlp as nlp\n",
    "import mxnet as mx\n",
    "\n",
    "# Load a Small BERT model\n",
    "model, vocab = nlp.model.get_model('bert_12_768_12', dataset_name='book_corpus_wiki_en_uncased', use_classifier=False, use_decoder=False);\n",
    "tokenizer = nlp.data.BERTTokenizer(vocab, lower=True);\n",
    "transform = nlp.data.BERTSentenceTransform(tokenizer, max_seq_length=512, pair=False, pad=False);\n",
    "\n",
    "# Transform Text\n",
    "sample = transform(['AWS Embark provides onboarding, training, and implementation support to launch your machine learning journey!']);\n",
    "words, valid_len, segments = mx.nd.array([sample[0]]), mx.nd.array([sample[1]]), mx.nd.array([sample[2]]);\n",
    "\n",
    "# Encode\n",
    "seq_encoding, cls_encoding = model(words, segments, valid_len);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step of using a transformer is to split the sentence into tokens for a vocabulary.  This is handled cleanly by Gluon, but we can look inside to see how it is split.  Notice that the model actually uses a subword vocabulary---where some words are split into constituant parts like \"onboarding\" becoming `'onboard'` and `'##ing'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]',\n",
       " 'aw',\n",
       " '##s',\n",
       " 'embark',\n",
       " 'provides',\n",
       " 'onboard',\n",
       " '##ing',\n",
       " ',',\n",
       " 'training',\n",
       " ',',\n",
       " 'and',\n",
       " 'implementation',\n",
       " 'support',\n",
       " 'to',\n",
       " 'launch',\n",
       " 'your',\n",
       " 'machine',\n",
       " 'learning',\n",
       " 'journey',\n",
       " '!',\n",
       " '[SEP]']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[vocab.to_tokens(int(w.asscalar())) for w in words[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at an embedding that can be used for downstream tasks like classification, called the `cls_embedding`.  The other term `seq_encoding` gives an encoding for each token in the sentence and can be used for tasks like machine translation or part-of-speach tagging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "[[-0.93319327 -0.64595526 -0.9838873   0.8745588   0.83370477 -0.27255702\n",
       "   0.83646435  0.5017094  -0.96900374 -0.99999803 -0.80741197  0.9707317\n",
       "   0.9694664   0.8220918   0.94080067 -0.8032321  -0.5185906  -0.68784434\n",
       "   0.5078429  -0.19376715  0.82072085  0.99999994 -0.4470562   0.46086797\n",
       "   0.72556126  0.9984201  -0.91346705  0.9421183   0.9667642   0.8444159\n",
       "  -0.7319919   0.4337138  -0.98731196 -0.42980403 -0.9875463  -0.99363977\n",
       "   0.6884772  -0.78827167 -0.02625772 -0.22823371 -0.9275603   0.49193987\n",
       "   0.99999875  0.3563488   0.8028779  -0.44576868 -1.          0.39309335\n",
       "  -0.8957847   0.99088544  0.9376737   0.97079736  0.4507445   0.71947384\n",
       "   0.67045027 -0.55917674  0.11889828  0.2813297  -0.45418862 -0.73720706\n",
       "  -0.6546041   0.5714999  -0.9635186  -0.91710484  0.98809004  0.9682401\n",
       "  -0.34150386 -0.41875562 -0.35155183  0.26857936  0.9030835   0.39205298\n",
       "  -0.4644852  -0.9238823   0.884571    0.5233499  -0.82955945  1.\n",
       "  -0.7029816  -0.9657539   0.9412182   0.9366446   0.75504905 -0.6918574\n",
       "   0.89721036 -1.          0.65010124 -0.27607647 -0.9889874   0.4626689\n",
       "   0.7802767  -0.4713516   0.870521    0.8258902  -0.66734654 -0.73490083\n",
       "  -0.41169593 -0.9608042  -0.6677574  -0.7181145   0.3794124  -0.42751917\n",
       "  -0.5431724  -0.5454463   0.6552708  -0.595954   -0.40307105  0.817905\n",
       "   0.25403142  0.74885577  0.7177549  -0.5865415   0.66027606 -0.9569844\n",
       "   0.8078067  -0.49553642 -0.99032474 -0.80507755 -0.98944235  0.67938244\n",
       "  -0.46893787 -0.49770465  0.9435711  -0.67601293  0.6242123  -0.35376137\n",
       "  -0.9798753  -1.         -0.88622874 -0.6232626  -0.3648232  -0.5397109\n",
       "  -0.96008855 -0.9581868   0.6929339   0.9596577   0.45467308  0.9999871\n",
       "  -0.5456944   0.9423536  -0.6679444  -0.89365673  0.8719971  -0.60190886\n",
       "   0.9491411   0.3322817  -0.6823258   0.35467675 -0.68724686  0.4883853\n",
       "  -0.90348005 -0.3923895  -0.9148107  -0.9420529  -0.5164532   0.95255756\n",
       "  -0.76869273 -0.9900086  -0.43021932 -0.3832206  -0.6836825   0.89035773\n",
       "   0.89778924  0.52179086 -0.5905326   0.5572294   0.47304702  0.7317423\n",
       "  -0.8223108  -0.42904496  0.60252804 -0.5553274  -0.9651199  -0.97113\n",
       "  -0.6269212   0.70916736  0.98933595  0.7617357   0.47267753  0.91341037\n",
       "  -0.36563197  0.8400085  -0.9661789   0.9792463  -0.381218    0.40798473\n",
       "  -0.6195433   0.8365727  -0.89160717  0.43854037  0.85761017 -0.89349633\n",
       "  -0.8460469  -0.33353445 -0.6238915  -0.6237878  -0.91895276  0.78934556\n",
       "  -0.45468566 -0.37098518 -0.2802347   0.9389639   0.9783244   0.8375167\n",
       "   0.78662205  0.911309   -0.86075485 -0.5208832   0.31762612  0.44489014\n",
       "   0.37682664  0.99232525 -0.84560734 -0.35030586 -0.9371138  -0.9839039\n",
       "   0.18226352 -0.9049515  -0.44366583 -0.88333255  0.8802967  -0.6866107\n",
       "   0.7515006   0.51572514 -0.9534735  -0.7654856   0.56441724 -0.7118029\n",
       "   0.6507125  -0.42600206  0.9144928   0.99068284 -0.7518239   0.4034217\n",
       "   0.95724577 -0.9576429  -0.87025225  0.6872016  -0.5365873   0.89151543\n",
       "  -0.75573236  0.9945442   0.98580754  0.93751776 -0.89198375 -0.93619245\n",
       "  -0.8617939  -0.83944386 -0.07806284  0.61417925  0.9757287   0.86545604\n",
       "   0.6195351  -0.02958431 -0.7793393   0.9932633  -0.9033832  -0.94816375\n",
       "  -0.6934367  -0.3550962  -0.98432606  0.951692    0.602991    0.6868308\n",
       "  -0.7219121  -0.8239507  -0.9522702   0.9019956   0.42346007  0.9830559\n",
       "  -0.53214526 -0.933522   -0.7790559  -0.94539016  0.08941139 -0.43432158\n",
       "  -0.7561082   0.16752538 -0.9465671   0.66098404  0.6052085   0.71403885\n",
       "  -0.9727605   0.99922854  1.          0.96381634  0.9015783   0.88901865\n",
       "  -0.9999982  -0.8104924   0.9999992  -0.99912894 -1.         -0.89495337\n",
       "  -0.5616007   0.44234407 -1.         -0.37967134 -0.10486434 -0.9079379\n",
       "   0.8848403   0.97247094  0.98594457 -1.          0.8617057   0.96603477\n",
       "  -0.83498305  0.9907034  -0.61170673  0.9584219   0.60830134  0.5979497\n",
       "  -0.46878514  0.61816645 -0.9798165  -0.9127305  -0.8825705  -0.9210441\n",
       "   0.9999709   0.4259574  -0.9182108  -0.91386425  0.76479137 -0.2745672\n",
       "  -0.08099614 -0.9570967  -0.46897468  0.8074626   0.868723    0.49567413\n",
       "   0.5045743  -0.6708434   0.44123018  0.50581264  0.36183852  0.83276737\n",
       "  -0.9235329  -0.6635188  -0.66113675  0.46687862 -0.8693267  -0.97415555\n",
       "   0.9602559  -0.64504105  0.94177234  1.          0.6758578  -0.90384024\n",
       "   0.784895    0.45858318 -0.35627753  1.          0.9425872  -0.97165215\n",
       "  -0.8125229   0.7806421  -0.81481534 -0.8446586   0.9997686  -0.53493685\n",
       "  -0.9420746  -0.7050732   0.9731713  -0.9853222   0.99977666 -0.8421051\n",
       "  -0.9716732   0.9402028   0.9333916  -0.84282064 -0.8042236   0.402305\n",
       "  -0.90480363  0.5653063  -0.90051323  0.81264234  0.4968196  -0.3284355\n",
       "   0.866193   -0.78215057 -0.79869044  0.38222003 -0.8737796  -0.42680302\n",
       "   0.98594004  0.6802295  -0.43802795  0.22762935 -0.5040965  -0.6120762\n",
       "  -0.9738393   0.7656392   1.         -0.42923886  0.93913776 -0.5358515\n",
       "  -0.31916392  0.28585115  0.71039456  0.7702251  -0.37945846 -0.9144298\n",
       "   0.9415248  -0.96339494 -0.98390174  0.73170936  0.4143451  -0.35970992\n",
       "   0.99999994  0.66465735  0.49598193  0.66311187  0.9990493   0.18004389\n",
       "   0.5764407   0.9850691   0.9859065  -0.31025413  0.77371544  0.838695\n",
       "  -0.97798526 -0.42488405 -0.76547074  0.27132404 -0.9304512  -0.0828347\n",
       "  -0.95238614  0.9726561   0.9937458   0.6515355   0.5132978   0.875426\n",
       "   1.         -0.9278796   0.6354646   0.37594822  0.6476919  -0.99999416\n",
       "  -0.79900515 -0.4819231  -0.28321347 -0.95319366 -0.5629679   0.47787428\n",
       "  -0.9713713   0.9505604   0.8715223  -0.98982453 -0.980455   -0.78147596\n",
       "   0.8284094   0.1692326  -0.9988373  -0.7752999  -0.6030291   0.6897489\n",
       "  -0.4415794  -0.93083864 -0.68040663 -0.6141768   0.73514754 -0.33970433\n",
       "   0.71313256  0.971288    0.56579924 -0.9476036  -0.5136867  -0.22601436\n",
       "  -0.84540373  0.88575244 -0.9142676  -0.9840157  -0.41753092  1.\n",
       "  -0.43543684  0.9791822   0.81038594  0.72911274 -0.48710054  0.36918524\n",
       "   0.9898705   0.40322182 -0.9417709  -0.986623   -0.44174957 -0.7360659\n",
       "   0.7803187   0.8422428   0.9055444   0.78990746  0.933011    0.5311136\n",
       "  -0.15972914  0.01065459  0.99959147 -0.3959978  -0.35900128 -0.7809881\n",
       "  -0.35013375 -0.5434308  -0.21140401  1.          0.38729373  0.85250074\n",
       "  -0.98761404 -0.95233613 -0.95523053  1.          0.89868927 -0.72879344\n",
       "   0.7029387   0.7115878  -0.3251468   0.82999843 -0.29108065 -0.5763777\n",
       "   0.6018535   0.37022972  0.95302486 -0.76353437 -0.9735665  -0.79936963\n",
       "   0.6202991  -0.9650738   0.9999991  -0.72781634 -0.535784   -0.5513955\n",
       "  -0.6234547  -0.47941035  0.14638579 -0.9766408  -0.277152    0.53553027\n",
       "   0.9602495   0.5458042  -0.8035575  -0.94136786  0.9696411   0.85432553\n",
       "  -0.9881191  -0.9271181   0.9505855  -0.98017496  0.7590584   1.\n",
       "   0.6571057   0.52459675  0.29902112 -0.57537645  0.56847817 -0.7250466\n",
       "   0.7785395  -0.9533516  -0.51316327 -0.5053966   0.6266473  -0.44968387\n",
       "  -0.76576686  0.6685817   0.44771588 -0.69561195 -0.7944159  -0.14176977\n",
       "   0.6375518   0.91727173 -0.4964272  -0.36475325  0.23161863 -0.12322422\n",
       "  -0.9325899  -0.53537595 -0.59127074 -1.          0.7974218  -1.\n",
       "   0.72820365  0.6049616  -0.38108146  0.8004656   0.7163387   0.8647911\n",
       "  -0.73120624 -0.9840126   0.28321394  0.7671534  -0.5953087  -0.7030712\n",
       "  -0.69396544  0.4880789  -0.23214337  0.4346002  -0.8834376   0.87329465\n",
       "  -0.43924725  1.          0.39510933 -0.77048814 -0.95216554  0.39385462\n",
       "  -0.41253865  1.         -0.8044968  -0.9587769   0.5984927  -0.921092\n",
       "  -0.8688963   0.61945736  0.05316148 -0.89191055 -0.9875876   0.94325835\n",
       "   0.9496206  -0.761406    0.7338442  -0.5655679  -0.78769916  0.27038318\n",
       "   0.9809261   0.9796121   0.57993245  0.829014   -0.7294103  -0.5553074\n",
       "   0.96550685  0.39583126  0.4267756   0.47864977  1.          0.5850463\n",
       "  -0.9093591   0.18200855 -0.95153666 -0.46324757 -0.9586769   0.44050574\n",
       "   0.5212367   0.9507589  -0.49623463  0.9528107  -0.95962274  0.23845646\n",
       "  -0.88576686 -0.83176196  0.5838706  -0.9452644  -0.9747682  -0.97651964\n",
       "   0.82783437 -0.5392877  -0.4171739   0.3849798   0.31628677  0.7016687\n",
       "   0.63838243 -1.          0.9563416   0.58744824  0.98245263  0.94750994\n",
       "   0.9106757   0.7632961   0.5551099  -0.97887015 -0.96468616 -0.47253078\n",
       "  -0.4132273   0.81875414  0.84436727  0.87757725  0.5923616  -0.673246\n",
       "  -0.5812038  -0.8544027  -0.9123912  -0.99192804  0.6580095  -0.8746632\n",
       "  -0.91838497  0.9705242   0.30353752 -0.38100928 -0.59278035 -0.94969195\n",
       "   0.9373759   0.8732209   0.42236823  0.19275683  0.7024338   0.88051194\n",
       "   0.9497211   0.97485805 -0.9590023   0.8923835  -0.92637897  0.6155076\n",
       "   0.91115296 -0.95734096  0.3051938   0.76125693 -0.5412008   0.44467083\n",
       "  -0.5035234  -0.92639315  0.8506577  -0.38057816  0.58557963 -0.5290223\n",
       "  -0.21801865 -0.68833476 -0.3236634  -0.77152765 -0.798871    0.78614646\n",
       "   0.40541837  0.8961469   0.9224514  -0.34413517 -0.81121975 -0.39636025\n",
       "  -0.9209506  -0.90922993  0.8750322  -0.28593576 -0.7291578   0.8959636\n",
       "   0.1517115   0.8933077   0.27605492 -0.5201868  -0.5661766  -0.71194935\n",
       "   0.889251   -0.6446037  -0.7911608  -0.760652    0.8006387   0.48150605\n",
       "   0.99999994 -0.91071534 -0.9772713  -0.7576515  -0.6136789   0.5645322\n",
       "  -0.73964405 -1.          0.5839554  -0.86396825  0.87006015 -0.8810205\n",
       "   0.88817227 -0.88502914 -0.9806066  -0.5544585   0.8171493   0.96350086\n",
       "  -0.6971365  -0.83380437  0.78213793 -0.834305    0.99654377  0.8176711\n",
       "  -0.69926965 -0.12661274  0.8168385  -0.9347744  -0.8247555   0.84738064]]\n",
       "<NDArray 1x768 @cpu(0)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_encoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
