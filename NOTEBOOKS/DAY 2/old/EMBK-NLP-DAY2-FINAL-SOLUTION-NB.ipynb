{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Project Day 2 Solution: Tree-based Models and Regression Models for a Classification Task\n",
    "\n",
    "We continue to work with the final project dataset to see how Tree-based models (Decision Tree, Random Forest) and Regression Models, along with efficient optimization techniques (GridSearch, RandomizedSearch), perform to predict the __isPositive__ field of the dataset.\n",
    "\n",
    "1. Reading the dataset\n",
    "2. Exploratory data analysis and missing value imputation\n",
    "3. Stop word removal and stemming\n",
    "4. Splitting the training dataset into training and validation\n",
    "5. Computing Bag of Words features\n",
    "6. Fitting a classifier (with hyperparameter tuning) and checking the model performance\n",
    "    * Find more details on the __LogisticRegression__ here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "    * Find more details on the __DecisionTreeClassifier__ here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "    * Find more details on the __RandomForestClassifier__ here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "    * Find more details on the __GridSearchCV__ here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html\n",
    "    * Find more details on the __RandomizedSearchCV__ here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "7. Ideas for improvement\n",
    "\n",
    "*Note: Incorporate all that you have learned over Day 1 and Day 2. Feel free to use your processed data from Day 1 to save on redundant work (1-5).*\n",
    "\n",
    "Overall dataset schema:\n",
    "* __reviewText:__ Text of the review\n",
    "* __summary:__ Summary of the review\n",
    "* __verified:__ Whether the purchase was verified (True or False)\n",
    "* __time:__ UNIX timestamp for the review\n",
    "* __log_votes:__ Logarithm-adjusted votes log(1+votes)\n",
    "* __isPositive:__ Rating of the review\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Reading the datasets\n",
    "\n",
    "We will use the __pandas__ library to read our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved\n",
    "# SPDX-License-Identifier: MIT-0\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('../../DATA/NLP/EMBK-NLP-FINAL-TRAIN-CSV.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the first five rows of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>log_votes</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...</td>\n",
       "      <td>IDEAL FOR BEGINNER!</td>\n",
       "      <td>True</td>\n",
       "      <td>1361836800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>unable to open or use</td>\n",
       "      <td>Two Stars</td>\n",
       "      <td>True</td>\n",
       "      <td>1452643200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Waste of money!!! It wouldn't load to my system.</td>\n",
       "      <td>Dont buy it!</td>\n",
       "      <td>True</td>\n",
       "      <td>1433289600</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I attempted to install this OS on two differen...</td>\n",
       "      <td>I attempted to install this OS on two differen...</td>\n",
       "      <td>True</td>\n",
       "      <td>1518912000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I've spent 14 fruitless hours over the past tw...</td>\n",
       "      <td>Do NOT Download.</td>\n",
       "      <td>True</td>\n",
       "      <td>1441929600</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  PURCHASED FOR YOUNGSTER WHO\\nINHERITED MY \"TOO...   \n",
       "1                              unable to open or use   \n",
       "2   Waste of money!!! It wouldn't load to my system.   \n",
       "3  I attempted to install this OS on two differen...   \n",
       "4  I've spent 14 fruitless hours over the past tw...   \n",
       "\n",
       "                                             summary  verified        time  \\\n",
       "0                                IDEAL FOR BEGINNER!      True  1361836800   \n",
       "1                                          Two Stars      True  1452643200   \n",
       "2                                       Dont buy it!      True  1433289600   \n",
       "3  I attempted to install this OS on two differen...      True  1518912000   \n",
       "4                                   Do NOT Download.      True  1441929600   \n",
       "\n",
       "   log_votes  isPositive  \n",
       "0   0.000000         1.0  \n",
       "1   0.000000         0.0  \n",
       "2   0.000000         0.0  \n",
       "3   0.000000         0.0  \n",
       "4   1.098612         0.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_test = pd.read_csv('../../DATA/NLP/EMBK-NLP-FINAL-TEST-CSV.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>summary</th>\n",
       "      <th>verified</th>\n",
       "      <th>time</th>\n",
       "      <th>log_votes</th>\n",
       "      <th>isPositive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kaspersky offers the best security for your co...</td>\n",
       "      <td>State of the art protection</td>\n",
       "      <td>True</td>\n",
       "      <td>1465516800</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This Value was extremely discounted which I ap...</td>\n",
       "      <td>Quickbooks</td>\n",
       "      <td>True</td>\n",
       "      <td>1393632000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Some dufus probably got stock options by the t...</td>\n",
       "      <td>Sad</td>\n",
       "      <td>False</td>\n",
       "      <td>1228176000</td>\n",
       "      <td>2.639057</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I have reviewed the software and it is beyond ...</td>\n",
       "      <td>Excellent product</td>\n",
       "      <td>True</td>\n",
       "      <td>1402531200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Plain old simple you need Anti-Virus,I have tr...</td>\n",
       "      <td>A must have</td>\n",
       "      <td>True</td>\n",
       "      <td>1367539200</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  \\\n",
       "0  Kaspersky offers the best security for your co...   \n",
       "1  This Value was extremely discounted which I ap...   \n",
       "2  Some dufus probably got stock options by the t...   \n",
       "3  I have reviewed the software and it is beyond ...   \n",
       "4  Plain old simple you need Anti-Virus,I have tr...   \n",
       "\n",
       "                       summary  verified        time  log_votes  isPositive  \n",
       "0  State of the art protection      True  1465516800   0.000000         1.0  \n",
       "1                   Quickbooks      True  1393632000   0.000000         1.0  \n",
       "2                          Sad     False  1228176000   2.639057         0.0  \n",
       "3            Excellent product      True  1402531200   0.000000         1.0  \n",
       "4                  A must have      True  1367539200   0.000000         1.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training dataset is: (70000, 6)\n",
      "The shape of the test dataset is: (8000, 6)\n"
     ]
    }
   ],
   "source": [
    "print('The shape of the training dataset is:', df_train.shape)\n",
    "print('The shape of the test dataset is:', df_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Exploratory data analysis and missing value imputation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the target distribution for our datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    43692\n",
       "0.0    26308\n",
       "Name: isPositive, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[\"isPositive\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0    4980\n",
       "0.0    3020\n",
       "Name: isPositive, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[\"isPositive\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the number of missing values:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    11\n",
      "summary       14\n",
      "verified       0\n",
      "time           0\n",
      "log_votes      0\n",
      "isPositive     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_train.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reviewText    2\n",
      "summary       1\n",
      "verified      0\n",
      "time          0\n",
      "log_votes     0\n",
      "isPositive    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df_test.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fill-in a placeholder for the __reviewText__ missing values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"reviewText\"].fillna(\"Missing\", inplace=True)\n",
    "df_test[\"reviewText\"].fillna(\"Missing\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Stop word removal and stemming\n",
    "\n",
    "We will apply the text processing methods discussed in the class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/ec2-user/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Install the library and functions\n",
    "import nltk\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk, re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop = stopwords.words('english')\n",
    "\n",
    "# These words are important for our problem. We don't want to remove them.\n",
    "excluding = ['against', 'not', 'don', \"don't\",'ain', 'aren', \"aren't\", 'couldn', \"couldn't\",\n",
    "             'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", \n",
    "             'haven', \"haven't\", 'isn', \"isn't\", 'mightn', \"mightn't\", 'mustn', \"mustn't\",\n",
    "             'needn', \"needn't\",'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \n",
    "             \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n",
    "\n",
    "stop_words = [word for word in stop if word not in excluding]\n",
    "\n",
    "snow = SnowballStemmer('english')\n",
    "\n",
    "def process_text(texts): \n",
    "    final_text_list=[]\n",
    "    for sent in texts:\n",
    "        filtered_sentence=[]\n",
    "        \n",
    "        sent = sent.lower() # Lowercase \n",
    "        sent = sent.strip() # Remove leading/trailing whitespace\n",
    "        sent = re.sub('\\s+', ' ', sent) # Remove extra space and tabs\n",
    "        sent = re.compile('<.*?>').sub('', sent) # Remove HTML tags/markups:\n",
    "        \n",
    "        for w in word_tokenize(sent):\n",
    "            # Check if it is not numeric and its length>2 and not in stop words\n",
    "            if(not w.isnumeric()) and (len(w)>2) and (w not in stop_words):  \n",
    "                # Stem and add to filtered list\n",
    "                filtered_sentence.append(snow.stem(w))\n",
    "        final_string = \" \".join(filtered_sentence) #final string of cleaned words\n",
    " \n",
    "        final_text_list.append(final_string)\n",
    "    \n",
    "    return final_text_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing training reviewText\n",
      "Pre-processing test reviewText\n"
     ]
    }
   ],
   "source": [
    "print(\"Pre-processing training reviewText\")\n",
    "df_train[\"reviewText\"] = process_text(df_train[\"reviewText\"].tolist())\n",
    "\n",
    "print(\"Pre-processing test reviewText\")\n",
    "df_test[\"reviewText\"] = process_text(df_test[\"reviewText\"].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Splitting the training dataset into training and validation\n",
    "\n",
    "Sklearn library has a useful function to split datasets. We will use the __train_test_split()__ function. In the example below, we get 90% of the data for training and 10% is left for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[\"reviewText\"].tolist(), \n",
    "                                                  df_train[\"isPositive\"].tolist(), \n",
    "                                                  test_size=0.10, \n",
    "                                                  shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Computing Bag of Words features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "\n",
    "X_test = df_test[\"reviewText\"].tolist()\n",
    "y_test = df_test[\"isPositive\"].tolist()\n",
    "\n",
    "# Initialize the binary count vectorizer\n",
    "tfidf_vectorizer = CountVectorizer(binary=True,\n",
    "                                   max_features=50  # Limit the vocabulary size\n",
    "                                  )\n",
    "# Fit and transform\n",
    "X_train_text_vectors = tfidf_vectorizer.fit_transform(X_train)\n",
    "# Only transform\n",
    "X_val_text_vectors = tfidf_vectorizer.transform(X_val)\n",
    "# Only transform\n",
    "X_test_text_vectors = tfidf_vectorizer.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Fitting a classifier (with hyperparameter tuning) and checking the model performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.1 LogisticRegression \n",
    "\n",
    "Using the __LogisticRegression__ from here: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "Using the __RandomizedSearchCV__ from here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 6 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'penalty': 'l2', 'C': 0.02}\n",
      "Best score:  0.7541428571428571\n",
      "LR with RandomizedSearchCV on Validation: Accuracy Score: 0.748714, F1-score: 0.796953\n",
      "LR with RandomizedSearchCV on Test: Accuracy Score: 0.748750, F1-score: 0.795773\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "lrClassifier = LogisticRegression(class_weight = 'balanced')\n",
    "parameters = {'penalty': ['l2', 'l1'],\n",
    "              'C': [0.01, 0.02, 0.05]}\n",
    "\n",
    "# NOTE: RandomizedSearchCV uses by default the score function of the estimator to evaluate\n",
    "# (r2_score for regression; accuracy_score for classification). If desired,\n",
    "# other scoring functions can be specified via the 'scoring' parameter. \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "# NOTE: You can experiment with different cv numbers, default = 5\n",
    "# NOTE: You can also experiment with different n_iter\n",
    "# (number of parameter settings that are sampled by the RandomizedSearch), default = 10\n",
    "lrClassifier_rand = RandomizedSearchCV(lrClassifier,\n",
    "                                       parameters,\n",
    "                                       cv=5,\n",
    "                                       verbose=1,\n",
    "                                       n_jobs=-1)\n",
    "lrClassifier_rand.fit(X_train_text_vectors, y_train)\n",
    "\n",
    "print(\"Best parameters: \", lrClassifier_rand.best_params_)\n",
    "print(\"Best score: \", lrClassifier_rand.best_score_)\n",
    "\n",
    "lrClassifier_rand_val_predictions = lrClassifier_rand.predict(X_val_text_vectors)\n",
    "lrClassifier_rand_test_predictions = lrClassifier_rand.predict(X_test_text_vectors)\n",
    "\n",
    "print(\"LR with RandomizedSearchCV on Validation: Accuracy Score: %f, F1-score: %f\" % \\\n",
    "      (accuracy_score(y_val, lrClassifier_rand_val_predictions), f1_score(y_val, lrClassifier_rand_val_predictions)))\n",
    "print(\"LR with RandomizedSearchCV on Test: Accuracy Score: %f, F1-score: %f\" % \\\n",
    "      (accuracy_score(y_test, lrClassifier_rand_test_predictions), f1_score(y_test, lrClassifier_rand_test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.2 DecisionTreeClassifier \n",
    "\n",
    "Using the __DecisionTreeClassifier__ from here: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html\n",
    "\n",
    "Using the __RandomizedSearchCV__ from here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 9 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   49.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'min_samples_leaf': 25, 'max_depth': 10}\n",
      "Best score:  0.732904761904762\n",
      "DTClassifier with RandomizedSearchCV on Validation: Accuracy Score: 0.730143, F1-score: 0.777267\n",
      "DTClassifier with RandomizedSearchCV on Test: Accuracy Score: 0.734375, F1-score: 0.779770\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "dtClassifier = DecisionTreeClassifier(class_weight = 'balanced')\n",
    "parameters = {'max_depth': [10, 20, 30],\n",
    "              'min_samples_leaf': [5, 15, 25]}\n",
    "\n",
    "# NOTE: RandomizedSearchCV uses by default the score function of the estimator to evaluate\n",
    "# (r2_score for regression; accuracy_score for classification). If desired,\n",
    "# other scoring functions can be specified via the 'scoring' parameter. \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "# NOTE: You can experiment with different cv numbers, default = 5\n",
    "# NOTE: You can also experiment with different n_iter\n",
    "# (number of parameter settings that are sampled by the RandomizedSearch), default = 10\n",
    "dtClassifier_rand = RandomizedSearchCV(dtClassifier,\n",
    "                                       parameters,\n",
    "                                       cv=5,\n",
    "                                       verbose=1,\n",
    "                                       n_jobs=-1)\n",
    "dtClassifier_rand.fit(X_train_text_vectors, y_train)\n",
    "\n",
    "print(\"Best parameters: \", dtClassifier_rand.best_params_)\n",
    "print(\"Best score: \", dtClassifier_rand.best_score_)\n",
    "\n",
    "dtClassifier_rand_val_predictions = dtClassifier_rand.predict(X_val_text_vectors)\n",
    "dtClassifier_rand_test_predictions = dtClassifier_rand.predict(X_test_text_vectors)\n",
    "\n",
    "print(\"DTClassifier with RandomizedSearchCV on Validation: Accuracy Score: %f, F1-score: %f\" % \\\n",
    "      (accuracy_score(y_val, dtClassifier_rand_val_predictions), f1_score(y_val, dtClassifier_rand_val_predictions)))\n",
    "print(\"DTClassifier with RandomizedSearchCV on Test: Accuracy Score: %f, F1-score: %f\" % \\\n",
    "      (accuracy_score(y_test, dtClassifier_rand_test_predictions), f1_score(y_test, dtClassifier_rand_test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6.3 RandomForestClassifier \n",
    "\n",
    "Using the __RandomForestClassifier__ from here: https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "\n",
    "Using the __RandomizedSearchCV__ from here: https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.RandomizedSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  46 tasks      | elapsed: 22.0min\n",
      "[Parallel(n_jobs=-1)]: Done  50 out of  50 | elapsed: 23.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters:  {'n_estimators': 200, 'min_samples_leaf': 15, 'max_depth': 10}\n",
      "Best score:  0.7462063492063492\n",
      "RFClassifier with RandomizedSearchCV on Validation: Accuracy Score: 0.744286, F1-score: 0.792102\n",
      "RFClassifier with RandomizedSearchCV on Test: Accuracy Score: 0.748500, F1-score: 0.793810\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "rfClassifier = RandomForestClassifier(class_weight = 'balanced')\n",
    "parameters = {'n_estimators': [200, 300, 400],\n",
    "              'max_depth': [10, 20],\n",
    "              'min_samples_leaf': [15, 25]}\n",
    "\n",
    "# NOTE: RandomizedSearchCV uses by default the score function of the estimator to evaluate\n",
    "# (r2_score for regression; accuracy_score for classification). If desired,\n",
    "# other scoring functions can be specified via the 'scoring' parameter. \n",
    "# https://scikit-learn.org/stable/modules/model_evaluation.html#scoring-parameter\n",
    "\n",
    "# NOTE: You can experiment with different cv numbers, default = 5\n",
    "# NOTE: You can also experiment with different n_iter\n",
    "# (number of parameter settings that are sampled by the RandomizedSearch), default = 10\n",
    "rfClassifier_rand = RandomizedSearchCV(rfClassifier,\n",
    "                                       parameters,\n",
    "                                       cv=5,\n",
    "                                       verbose=1,\n",
    "                                       n_jobs=-1)\n",
    "rfClassifier_rand.fit(X_train_text_vectors, y_train)\n",
    "\n",
    "print(\"Best parameters: \", rfClassifier_rand.best_params_)\n",
    "print(\"Best score: \", rfClassifier_rand.best_score_)\n",
    "\n",
    "rfClassifier_rand_val_predictions = rfClassifier_rand.predict(X_val_text_vectors)\n",
    "rfClassifier_rand_test_predictions = rfClassifier_rand.predict(X_test_text_vectors)\n",
    "\n",
    "print(\"RFClassifier with RandomizedSearchCV on Validation: Accuracy Score: %f, F1-score: %f\" % \\\n",
    "      (accuracy_score(y_val, rfClassifier_rand_val_predictions), f1_score(y_val, rfClassifier_rand_val_predictions)))\n",
    "print(\"RFClassifier with RandomizedSearchCV on Test: Accuracy Score: %f, F1-score: %f\" % \\\n",
    "      (accuracy_score(y_test, rfClassifier_rand_test_predictions), f1_score(y_test, rfClassifier_rand_test_predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Ideas for improvement\n",
    "\n",
    "**Preprocessing**: We can usually improve performance with some additional work. You can try the following:\n",
    "* Change the feature extractor to TF, TF-IDF. Also experiment with different vocabulary size.\n",
    "* Add the other text field __summary__ to the model and get bag of words features of it.\n",
    "* Come up with some other features such as having certain punctuations, all-capitalized words or some words that might be useful in this problem.\n",
    "\n",
    "**Hyperparameter Tuning**: \n",
    "* Always a good idea to try other parameter ranges and/or combinations of parameters, including threshold calibration. \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
