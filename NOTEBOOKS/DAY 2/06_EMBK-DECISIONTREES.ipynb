{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Model\n",
    "\n",
    "In this notebook, we build, train a [__Decision Tree Classifier__](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) to predict the __Outcome Type__ field of our review dataset.\n",
    "\n",
    "\n",
    "1. <a href=\"#1\">Read the dataset</a>\n",
    "2. <a href=\"#2\">Exploratory Data Analysis</a>\n",
    "3. <a href=\"#3\">Select features to build the model</a>\n",
    "4. <a href=\"#4\">Training and test datasets</a>\n",
    "5. <a href=\"#5\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "6. <a href=\"#6\">Train a classifier</a>\n",
    "7. <a href=\"#7\">Test the classifier</a>\n",
    "8. <a href=\"#8\">Improvement ideas</a>\n",
    "\n",
    "__Austin Animal Center Dataset__:\n",
    "\n",
    "In this exercise, we are working with pet adoption data from __Austin Animal Center__. We have two datasets that cover intake and outcome of animals. Intake data is available from [here](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Intakes/wter-evkm) and outcome is from [here](https://data.austintexas.gov/Health-and-Community-Services/Austin-Animal-Center-Outcomes/9t4d-g238). \n",
    "\n",
    "In order to work with a single table, we joined the intake and outcome tables using the \"Animal ID\" column and created a single __review.csv__ file. We also didn't consider animals with multiple entries to the facility to keep our dataset simple. If you want to see the original datasets and the merged data with multiple entries, they are available under data/review folder: Austin_Animal_Center_Intakes.csv, Austin_Animal_Center_Outcomes.csv and Austin_Animal_Center_Intakes_Outcomes.csv.\n",
    "\n",
    "__Dataset schema:__ \n",
    "- __Pet ID__ - Unique ID of pet\n",
    "- __Outcome Type__ - State of pet at the time of recording the outcome (0 = not placed, 1 = placed). This is the field to predict.\n",
    "- __Sex upon Outcome__ - Sex of pet at outcome\n",
    "- __Name__ - Name of pet \n",
    "- __Found Location__ - Found location of pet before entered the center\n",
    "- __Intake Type__ - Circumstances bringing the pet to the center\n",
    "- __Intake Condition__ - Health condition of pet when entered the center\n",
    "- __Pet Type__ - Type of pet\n",
    "- __Sex upon Intake__ - Sex of pet when entered the center\n",
    "- __Breed__ - Breed of pet \n",
    "- __Color__ - Color of pet \n",
    "- __Age upon Intake Days__ - Age of pet when entered the center (days)\n",
    "- __Age upon Outcome Days__ - Age of pet at outcome (days)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (20.1.1)\n",
      "Requirement already up-to-date: scikit-learn in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (0.23.1)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.13.3 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-learn) (1.18.1)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.19.1 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-learn) (1.4.1)\n",
      "Requirement already satisfied, skipping upgrade: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-learn) (2.1.0)\n",
      "Requirement already satisfied, skipping upgrade: joblib>=0.11 in /home/ec2-user/anaconda3/envs/mxnet_p36/lib/python3.6/site-packages (from scikit-learn) (0.14.1)\n"
     ]
    }
   ],
   "source": [
    "#Upgrade dependencies\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. <a name=\"1\">Read the dataset</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's read the dataset into a dataframe, using Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the dataset is: (95485, 13)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "  \n",
    "df = pd.read_csv('../DATA/review/review_dataset.csv')\n",
    "\n",
    "print('The shape of the dataset is:', df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. <a name=\"2\">Exploratory Data Analysis</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We will look at number of rows, columns and some simple statistics of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pet ID</th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Sex upon Outcome</th>\n",
       "      <th>Name</th>\n",
       "      <th>Found Location</th>\n",
       "      <th>Intake Type</th>\n",
       "      <th>Intake Condition</th>\n",
       "      <th>Pet Type</th>\n",
       "      <th>Sex upon Intake</th>\n",
       "      <th>Breed</th>\n",
       "      <th>Color</th>\n",
       "      <th>Age upon Intake Days</th>\n",
       "      <th>Age upon Outcome Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A794011</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Chunk</td>\n",
       "      <td>Austin (TX)</td>\n",
       "      <td>Owner Surrender</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Brown Tabby/White</td>\n",
       "      <td>730</td>\n",
       "      <td>730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A776359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>Gizmo</td>\n",
       "      <td>7201 Levander Loop in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Dog</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Chihuahua Shorthair Mix</td>\n",
       "      <td>White/Brown</td>\n",
       "      <td>365</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A674754</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12034 Research in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Nursing</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Orange Tabby</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A689724</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>*Donatello</td>\n",
       "      <td>2300 Waterway Bnd in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Normal</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>Black</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A680969</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Neutered Male</td>\n",
       "      <td>*Zeus</td>\n",
       "      <td>4701 Staggerbrush Rd in Austin (TX)</td>\n",
       "      <td>Stray</td>\n",
       "      <td>Nursing</td>\n",
       "      <td>Cat</td>\n",
       "      <td>Intact Male</td>\n",
       "      <td>Domestic Shorthair Mix</td>\n",
       "      <td>White/Orange Tabby</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Pet ID  Outcome Type Sex upon Outcome        Name  \\\n",
       "0  A794011           1.0    Neutered Male       Chunk   \n",
       "1  A776359           1.0    Neutered Male       Gizmo   \n",
       "2  A674754           0.0      Intact Male         NaN   \n",
       "3  A689724           1.0    Neutered Male  *Donatello   \n",
       "4  A680969           1.0    Neutered Male       *Zeus   \n",
       "\n",
       "                        Found Location      Intake Type Intake Condition  \\\n",
       "0                          Austin (TX)  Owner Surrender           Normal   \n",
       "1    7201 Levander Loop in Austin (TX)            Stray           Normal   \n",
       "2        12034 Research in Austin (TX)            Stray          Nursing   \n",
       "3     2300 Waterway Bnd in Austin (TX)            Stray           Normal   \n",
       "4  4701 Staggerbrush Rd in Austin (TX)            Stray          Nursing   \n",
       "\n",
       "  Pet Type Sex upon Intake                    Breed               Color  \\\n",
       "0      Cat   Neutered Male   Domestic Shorthair Mix   Brown Tabby/White   \n",
       "1      Dog     Intact Male  Chihuahua Shorthair Mix         White/Brown   \n",
       "2      Cat     Intact Male   Domestic Shorthair Mix        Orange Tabby   \n",
       "3      Cat     Intact Male   Domestic Shorthair Mix               Black   \n",
       "4      Cat     Intact Male   Domestic Shorthair Mix  White/Orange Tabby   \n",
       "\n",
       "   Age upon Intake Days  Age upon Outcome Days  \n",
       "0                   730                    730  \n",
       "1                   365                    365  \n",
       "2                     6                      6  \n",
       "3                    60                     60  \n",
       "4                     7                     60  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the first five rows\n",
    "# NaN means missing data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 95485 entries, 0 to 95484\n",
      "Data columns (total 13 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   Pet ID                 95485 non-null  object \n",
      " 1   Outcome Type           95485 non-null  float64\n",
      " 2   Sex upon Outcome       95484 non-null  object \n",
      " 3   Name                   59138 non-null  object \n",
      " 4   Found Location         95485 non-null  object \n",
      " 5   Intake Type            95485 non-null  object \n",
      " 6   Intake Condition       95485 non-null  object \n",
      " 7   Pet Type               95485 non-null  object \n",
      " 8   Sex upon Intake        95484 non-null  object \n",
      " 9   Breed                  95485 non-null  object \n",
      " 10  Color                  95485 non-null  object \n",
      " 11  Age upon Intake Days   95485 non-null  int64  \n",
      " 12  Age upon Outcome Days  95485 non-null  int64  \n",
      "dtypes: float64(1), int64(2), object(10)\n",
      "memory usage: 9.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# Let's see the data types and non-null values for each column\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Outcome Type</th>\n",
       "      <th>Age upon Intake Days</th>\n",
       "      <th>Age upon Outcome Days</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>95485.000000</td>\n",
       "      <td>95485.000000</td>\n",
       "      <td>95485.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.564005</td>\n",
       "      <td>703.436959</td>\n",
       "      <td>717.757313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.495889</td>\n",
       "      <td>1052.252197</td>\n",
       "      <td>1055.023160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>60.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>365.000000</td>\n",
       "      <td>365.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>730.000000</td>\n",
       "      <td>730.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>9125.000000</td>\n",
       "      <td>9125.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Outcome Type  Age upon Intake Days  Age upon Outcome Days\n",
       "count  95485.000000          95485.000000           95485.000000\n",
       "mean       0.564005            703.436959             717.757313\n",
       "std        0.495889           1052.252197            1055.023160\n",
       "min        0.000000              0.000000               0.000000\n",
       "25%        0.000000             30.000000              60.000000\n",
       "50%        1.000000            365.000000             365.000000\n",
       "75%        1.000000            730.000000             730.000000\n",
       "max        1.000000           9125.000000            9125.000000"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This prints basic statistics for numerical columns\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's separate model features and model target. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Pet ID', 'Outcome Type', 'Sex upon Outcome', 'Name', 'Found Location',\n",
      "       'Intake Type', 'Intake Condition', 'Pet Type', 'Sex upon Intake',\n",
      "       'Breed', 'Color', 'Age upon Intake Days', 'Age upon Outcome Days'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model features:  Index(['Pet ID', 'Sex upon Outcome', 'Name', 'Found Location', 'Intake Type',\n",
      "       'Intake Condition', 'Pet Type', 'Sex upon Intake', 'Breed', 'Color',\n",
      "       'Age upon Intake Days', 'Age upon Outcome Days'],\n",
      "      dtype='object')\n",
      "Model target:  Outcome Type\n"
     ]
    }
   ],
   "source": [
    "model_features = df.columns.drop('Outcome Type')\n",
    "model_target = 'Outcome Type'\n",
    "\n",
    "print('Model features: ', model_features)\n",
    "print('Model target: ', model_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can explore the features set further, figuring out first what features are numerical or categorical. Beware that some integer-valued features could actually be categorical features, and some categorical features could be text features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numerical columns: Index(['Age upon Intake Days', 'Age upon Outcome Days'], dtype='object')\n",
      "\n",
      "Categorical columns: Index(['Pet ID', 'Sex upon Outcome', 'Name', 'Found Location', 'Intake Type',\n",
      "       'Intake Condition', 'Pet Type', 'Sex upon Intake', 'Breed', 'Color'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "numerical_features_all = df[model_features].select_dtypes(include=np.number).columns\n",
    "print('Numerical columns:',numerical_features_all)\n",
    "\n",
    "print('')\n",
    "\n",
    "categorical_features_all = df[model_features].select_dtypes(include='object').columns\n",
    "print('Categorical columns:',categorical_features_all)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target distribution\n",
    "\n",
    "Let's check our target distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "df[model_target].value_counts().plot.bar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the target plots we can identify whether or not we are dealing with imbalanced datasets - this means one result type is dominating the other one(s). \n",
    "\n",
    "Handling class imbalance is highly recommended, as the model performance can be greatly impacted. In particular the model may not work well for the infrequent classes, as there are not enough samples to learn patterns from, and so it would be hard for the classifier to identify and match those patterns. \n",
    "\n",
    "We might want to downsample the dominant class or upsample the rare the class, to help with learning its patterns. However, we should only fix the imbalance in training set, without changing the validation and test sets, as these should follow the original distribution. We will perform this task after train/test split. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. <a name=\"3\">Select features to build the model</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "This time we build a model using all features. That is, we build a classifier including __numerical, categorical__ and __text__ features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grab model features/inputs and target/output\n",
    "\n",
    "# can also grab less numerical features, as some numerical data might not be very useful\n",
    "numerical_features = ['Age upon Intake Days', 'Age upon Outcome Days']\n",
    "\n",
    "# dropping the IDs features, RescuerID and PetID here \n",
    "categorical_features = ['Sex upon Outcome', 'Intake Type',\n",
    "       'Intake Condition', 'Pet Type', 'Sex upon Intake']\n",
    "\n",
    "# from EDA, select the text features\n",
    "text_features = ['Name', 'Found Location', 'Breed', 'Color']\n",
    "    \n",
    "model_features = numerical_features + categorical_features + text_features\n",
    "model_target = 'Outcome Type'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning numerical features "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age upon Intake Days\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age upon Outcome Days\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "for c in numerical_features:\n",
    "    print(c)\n",
    "    df[c].plot.hist(bins=5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If for some histograms the values are heavily placed in the first bin, it is good to check for outliers, either checking the min-max values of those particular features and/or explore value ranges."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age upon Intake Days\n",
      "min: 0 max: 9125\n",
      "Age upon Outcome Days\n",
      "min: 0 max: 9125\n"
     ]
    }
   ],
   "source": [
    "for c in numerical_features:\n",
    "    print(c)\n",
    "    print('min:', df[c].min(), 'max:', df[c].max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With __value_counts()__ function, we can increase the number of histogram bins to 10 for more bins for a more refined view of the numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age upon Intake Days\n",
      "(-9.126, 912.5]     74835\n",
      "(912.5, 1825.0]     10647\n",
      "(1825.0, 2737.5]     3471\n",
      "(2737.5, 3650.0]     3998\n",
      "(3650.0, 4562.5]     1234\n",
      "(4562.5, 5475.0]     1031\n",
      "(5475.0, 6387.5]      183\n",
      "(6387.5, 7300.0]       79\n",
      "(7300.0, 8212.5]        5\n",
      "(8212.5, 9125.0]        2\n",
      "Name: Age upon Intake Days, dtype: int64\n",
      "Age upon Outcome Days\n",
      "(-9.126, 912.5]     74642\n",
      "(912.5, 1825.0]     10699\n",
      "(1825.0, 2737.5]     3465\n",
      "(2737.5, 3650.0]     4080\n",
      "(3650.0, 4562.5]     1263\n",
      "(4562.5, 5475.0]     1061\n",
      "(5475.0, 6387.5]      187\n",
      "(6387.5, 7300.0]       81\n",
      "(7300.0, 8212.5]        5\n",
      "(8212.5, 9125.0]        2\n",
      "Name: Age upon Outcome Days, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "for c in numerical_features: \n",
    "    print(c)\n",
    "    print(df[c].value_counts(bins=10, sort=False))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any outliers are identified as very likely wrong values, dropping them could improve the numerical values histograms, and later overall model performance. While a good rule of thumb is that anything not in the range of (Q1 - 1.5 IQR) and (Q3 + 1.5 IQR) is an outlier, other rules for removing 'outliers' should be considered as well. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check missing values for these numerical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Age upon Intake Days     0\n",
      "Age upon Outcome Days    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[numerical_features].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If any missing values, as a quick fix, we can apply mean imputation. This will replace the missing values with the mean value of the corresponding column.\n",
    "\n",
    "__Note__: The statistically correct way to perform mean/mode imputation before training an ML model is to compute the column-wise means on the training data only, and then use these values to impute missing data in both the train and test sets. So, you'll need to split your dataset first. Same goes for any other transformations we would like to apply to these numerical features, such as scaling. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning categorical features \n",
    "\n",
    "Let's also examine the categorical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex upon Outcome\n",
      "['Neutered Male' 'Intact Male' 'Intact Female' 'Unknown' 'Spayed Female'\n",
      " nan]\n",
      "Intake Type\n",
      "['Owner Surrender' 'Stray' 'Wildlife' 'Public Assist' 'Euthanasia Request'\n",
      " 'Abandoned']\n",
      "Intake Condition\n",
      "['Normal' 'Nursing' 'Sick' 'Injured' 'Aged' 'Feral' 'Pregnant' 'Other'\n",
      " 'Behavior' 'Medical']\n",
      "Pet Type\n",
      "['Cat' 'Dog' 'Other' 'Bird' 'Livestock']\n",
      "Sex upon Intake\n",
      "['Neutered Male' 'Intact Male' 'Intact Female' 'Unknown' 'Spayed Female'\n",
      " nan]\n"
     ]
    }
   ],
   "source": [
    "for c in categorical_features:\n",
    "    print(c)\n",
    "    print(df[c].unique()) #value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note on boolean type features__: Some categories might be of boolean type, like __False__ and __True__. The booleans will raise errors when trying to encode the categoricals with sklearn encoders, none of which accept boolean types. If using pandas get_dummies to one-hot encode the categoricals, there's no need to convert the booleans. However, get_dummies is trickier to use with sklearn's Pipeline and GridSearch. \n",
    "\n",
    "One way to deal with the booleans is to convert them to strings, by using a mask and a map changing only the booleans. Another way to handle the booleans is to convert them to strings by changing the type of all categoricals to 'str'. This will also affect the nans, basically performing imputation of the nans with a 'nans' placeholder value! \n",
    "\n",
    "Applying the type conversion to both categoricals and text features, takes care of the nans in the text fields as well. In case other imputations are planned for the categoricals and/or test fields, notice that the masking shown above leaves the nans unchanged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[categorical_features + text_features] = df[categorical_features + text_features].astype('str')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a check on missing values for the categorical features (and text features here)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex upon Outcome    0\n",
      "Intake Type         0\n",
      "Intake Condition    0\n",
      "Pet Type            0\n",
      "Sex upon Intake     0\n",
      "Name                0\n",
      "Found Location      0\n",
      "Breed               0\n",
      "Color               0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df[categorical_features + text_features].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting categoricals into useful numerical features will also have to wait until after the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cleaning text features \n",
    "\n",
    "Also a good idea to look at the text fields. Text cleaning can be performed here, before train/test split, with less code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name\n",
      "['Chunk' 'Gizmo' 'nan' ... '*Lingonberry' 'Guawp' '*Squanchy']\n",
      "Found Location\n",
      "['Austin (TX)' '7201 Levander Loop in Austin (TX)'\n",
      " '12034 Research in Austin (TX)' ... '4612 Sherwyn Drive in Austin (TX)'\n",
      " '16010 Voelker Ln in Austin (TX)' '2211 Santa Rita Street in Austin (TX)']\n",
      "Breed\n",
      "['Domestic Shorthair Mix' 'Chihuahua Shorthair Mix' 'Domestic Shorthair'\n",
      " ... 'Unknown' 'Bichon Frise/Lhasa Apso' 'Treeing Cur']\n",
      "Color\n",
      "['Brown Tabby/White' 'White/Brown' 'Orange Tabby' 'Black'\n",
      " 'White/Orange Tabby' 'Blue/White' 'Brown Tabby' 'Gray' 'Calico'\n",
      " 'Brown/Black' 'White/Tan' 'White' 'Brown' 'Black/White' 'Brown/White'\n",
      " 'Black/Brown' 'Chocolate/White' 'Red' 'White/White' 'Brown Brindle/White'\n",
      " 'Gray/Black' 'Tortie' 'Tan' 'White/Blue Tabby' 'Brown/Brown' 'Black/Gray'\n",
      " 'Blue' 'Cream Tabby' 'Brown/Gray' 'Blue Tabby/White' 'Red/White'\n",
      " 'Orange Tabby/White' 'Brown Merle/White' 'Tricolor' 'Apricot' 'Black/Tan'\n",
      " 'Tortie Point' 'Tan/Black' 'Torbie/Brown Tabby' 'White/Black'\n",
      " 'Blue Tabby' 'Blue Tick' 'White/Gray' 'Black/Tricolor' 'Chocolate/Tan'\n",
      " 'White/Brown Tabby' 'White/Brown Brindle' 'Lynx Point' 'Buff' 'Torbie'\n",
      " 'White/Buff' 'Brown Brindle' 'Cream' 'White/Blue' 'Blue/Tan'\n",
      " 'Black Brindle/White' 'Black/Yellow Brindle' 'Chocolate/Black'\n",
      " 'Black/Red' 'Fawn/White' 'Chocolate' 'Blue/Brown Brindle' 'Tan/White'\n",
      " 'Cream Tabby/White' 'Tan/Gray' 'Sable' 'Red/Buff' 'Blue Merle'\n",
      " 'Lynx Point/White' 'Yellow' 'Black/Brown Brindle' 'Brown/Tan'\n",
      " 'Silver Tabby' 'White/Red' 'Brown/Orange' 'Tricolor/White' 'Sable/Black'\n",
      " 'Gray/White' 'Orange/White' 'Brown Tiger/Brown' 'Brown Tabby/Black'\n",
      " 'Torbie/White' 'Yellow Brindle' 'Cream/White' 'Brown Brindle/Black'\n",
      " 'Black/Chocolate' 'Gold/White' 'White/Orange' 'Black Tabby'\n",
      " 'Tricolor/Brown' 'Seal Point/Gray' 'White/Tricolor' 'Silver/Tan'\n",
      " 'Gray Tabby/White' 'Black Brindle' 'Brown/Tricolor' 'Black Tabby/White'\n",
      " 'Yellow/White' 'Cream/Black' 'Gray/Tortie' 'Flame Point' 'Sable/White'\n",
      " 'Seal Point' 'Chocolate Point' 'Red/Tan' 'Gray/Tan' 'Calico Point/Gray'\n",
      " 'Black/Black' 'Red/Cream' 'White/Red Merle' 'Tortie/White' 'Red/Black'\n",
      " 'Green/Silver' 'Brown/Red' 'Gray Tabby' 'Green/Gray' 'Gray/Brown'\n",
      " 'Gray/Blue Merle' 'White/Blue Merle' 'Blue Cream' 'Silver Tabby/White'\n",
      " 'Black/Cream' 'Lilac Point' 'Gray Tabby/Black' 'Brown Merle' 'Gold/Cream'\n",
      " 'Gold' 'Blue Merle/Tricolor' 'Buff/White' 'White/Cream' 'Red Merle/White'\n",
      " 'Fawn/Black' 'Yellow/Yellow' 'Sable/Brown' 'Black/Black Tabby'\n",
      " 'White/Gray Tabby' 'Calico/White' 'Tricolor/Black' 'Fawn' 'Blue/Blue'\n",
      " 'White/Chocolate' 'Tan/Fawn' 'Blue Merle/White' 'Lynx Point/Blue'\n",
      " 'Blue Merle/Brown' 'Blue Merle/Tan' 'White/Seal Point' 'Liver/Tan'\n",
      " 'Blue Point/White' 'Liver/White' 'Chocolate Point/White' 'Gray/Pink'\n",
      " 'Black Brindle/Blue' 'Black Smoke' 'Brown Brindle/Red Tick' 'Cream/Brown'\n",
      " 'Black/Blue Tick' 'Red Tick/Blue Tick' 'White/Yellow' 'Orange'\n",
      " 'Torbie/Brown' 'Sable/Tan' 'Yellow Brindle/White' 'Gray/Orange'\n",
      " 'Calico Point' 'Red Tick' 'White/Red Tick' 'Blue Tick/Tan' 'Brown/Cream'\n",
      " 'Cream/Tan' 'Tan/Brown' 'Buff/Brown' 'Tan/Tan' 'Chocolate/Tricolor'\n",
      " 'Calico Point/White' 'Brown Brindle/Brown Brindle' 'Green/Brown'\n",
      " 'Black/Silver' 'White/Calico' 'Brown/Chocolate' 'Cream/Silver'\n",
      " 'White/Brown Merle' 'Red/Brown' 'White/Fawn' 'White/Gray Tiger'\n",
      " 'Tan/Gold' 'Tan/Red' 'Tan/Silver' 'Lilac Point/White' 'Buff/Black'\n",
      " 'Cream/Brown Merle' 'White/Black Brindle' 'Silver' 'Lilac Point/Gray'\n",
      " 'Black Smoke/White' 'Pink' 'Blue Tick/Tricolor' 'Blue Tick/Black'\n",
      " 'Seal Point/White' 'Blue Point' 'Silver/Brown' 'Fawn/Brown'\n",
      " 'Black Brindle/Brown' 'Blue Merle/Black' 'Blue Cream/White'\n",
      " 'White/Blue Cream' 'Gray/Gray' 'Tortie/Tortie' 'Green' 'Brown/Buff'\n",
      " 'Chocolate/Brown Tabby' 'Tortie/Blue Cream' 'Brown/Fawn' 'White/Tortie'\n",
      " 'Orange Tabby/Orange Tabby' 'Tortie/Black' 'White/Cream Tabby'\n",
      " 'Tan/Cream' 'Red/Yellow' 'Blue/Tortie' 'Lynx Point/Brown Tabby'\n",
      " 'Black Tabby/Orange' 'Blue/Tricolor' 'Black/Blue' 'White/Agouti'\n",
      " 'Gold/Yellow' 'Chocolate/Fawn' 'Orange/Orange Tabby'\n",
      " 'Tricolor/Blue Merle' 'Brown/Brown Tabby' 'Black/Orange'\n",
      " 'Cream/Blue Point' 'Calico/Tricolor' 'Agouti' 'Calico/Black'\n",
      " 'Brown Brindle/Brown' 'Lilac Point/Black' 'Tan/Blue Merle'\n",
      " 'Blue Tabby/Black' 'Silver/Black' 'Tan/Blue' 'Black/Yellow'\n",
      " 'Yellow/Green' 'Flame Point/Cream' 'Agouti/White' 'Brown/Green'\n",
      " 'Yellow/Black' 'Torbie/Blue Tabby' 'White/Black Tabby'\n",
      " 'Blue Merle/Red Merle' 'Cream/Orange' 'Gray/Cream' 'Silver/Chocolate'\n",
      " 'Tan/Tricolor' 'Red Merle' 'Chocolate/Cream' 'Tan/Buff'\n",
      " 'Brown Tiger/White' 'Blue/Gray' 'Gray Tabby/Gray' 'Chocolate/Red'\n",
      " 'Black Brindle/Black' 'Gray/Blue' 'Tricolor/Blue' 'Red Tick/Brown'\n",
      " 'Yellow/Blue' 'Gray/Yellow' 'Brown/Liver' 'Red/Red' 'Silver/Orange'\n",
      " 'Black/Pink' 'Tricolor/Tan' 'Calico/Brown' 'Tortie Point/Lynx Point'\n",
      " 'Cream/Blue' 'Green/Red' 'Tortie/Orange' 'Gray/Red' 'Black/Black Smoke'\n",
      " 'Buff/Tan' 'Brown/Yellow' 'Fawn/Blue' 'Red/Tricolor' 'Fawn/Cream'\n",
      " 'Silver/Red' 'Brown Tabby/Calico' 'Black/Blue Merle' 'Yellow/Orange'\n",
      " 'Brown Tabby/Brown' 'Blue Tick/Red' 'Seal Point/Cream'\n",
      " 'Cream Tabby/Orange' 'Chocolate/Blue Tick' 'Red/Blue'\n",
      " 'Blue Cream/Blue Tiger' 'Blue/Black' 'Brown Tiger' 'Brown Merle/Tan'\n",
      " 'Fawn/Tan' 'Brown Tabby/Orange' 'Blue Smoke' 'Red Tick/White'\n",
      " 'White/Apricot' 'White/Liver' 'Red/Gold' 'Green/Yellow' 'Red/Red Merle'\n",
      " 'Gold/Tan' 'Fawn/Tricolor' 'Blue Merle/Blue Merle' 'Red/Silver'\n",
      " 'Calico/Orange' 'Brown Tabby/Silver' 'Blue Tick/Red Tick'\n",
      " 'Orange Tabby/Brown' 'Apricot/Brown' 'Red/Red Tick' 'Gray/Tricolor'\n",
      " 'Black/Buff' 'Black/Green' 'Black/Black Brindle' 'Orange/Black'\n",
      " 'Tortie Point/White' 'White/Liver Tick' 'Gold/Brown' 'Red Merle/Black'\n",
      " 'Apricot/White' 'Brown Tabby/Brown Tabby' 'Cream/Seal Point'\n",
      " 'Tan/Red Merle' 'Gray/Green' 'Chocolate/Brown' 'Buff/Cream' 'Buff/Red'\n",
      " 'Brown/Silver' 'Blue Tick/Brown' 'Brown Tabby/Tortie' 'Blue Tiger/White'\n",
      " 'Tan/Chocolate Point' 'Black/Fawn' 'Blue/Brown' 'White/Blue Tick'\n",
      " 'Blue Tick/White' 'Orange Tabby/Orange' 'Blue Tick/Brown Brindle'\n",
      " 'White/Gold' 'Black Smoke/Brown Tabby' 'Red/Gray'\n",
      " 'Brown Brindle/Tricolor' 'Orange/Brown' 'Gray/Gold' 'Liver Tick/White'\n",
      " 'Black Smoke/Black Tiger' 'Brown/Red Merle' 'Sable/Buff'\n",
      " 'Gray Tabby/Brown Tabby' 'Gold/Silver' 'Seal Point/Brown'\n",
      " 'Silver Lynx Point' 'Black/Gold' 'Liver' 'Yellow/Tan' 'Blue Tiger'\n",
      " 'Tan/Yellow' 'Orange/Tan' 'Lynx Point/Tortie Point' 'Brown Tabby/Gray'\n",
      " 'Sable/Cream' 'White/Chocolate Point' 'White/Yellow Brindle'\n",
      " 'Black Tiger/White' 'Calico/Gray Tabby' 'Buff/Gray' 'Tricolor/Silver'\n",
      " 'Cream/Red' 'Gold/Buff' 'Liver Tick' 'Brown Brindle/Tan'\n",
      " 'Tricolor/Blue Tick' 'White/Pink' 'Sable/Gray' 'Brown/Brown Brindle'\n",
      " 'Orange Tabby/Tortie Point' 'Chocolate/Chocolate' 'Yellow/Gray'\n",
      " 'Chocolate Point/Cream' 'Black Brindle/Brown Brindle' 'Yellow/Cream'\n",
      " 'Gold/Black' 'Tan/Yellow Brindle' 'Red Tick/Tricolor'\n",
      " 'Brown Merle/Brown Tabby' 'Flame Point/White' 'Calico/Calico'\n",
      " 'Orange Tabby/Apricot' 'Blue/Calico' 'Brown/Black Smoke' 'Green/Black'\n",
      " 'Calico Point/Lynx Point' 'Torbie/Gray' 'Tortie/Calico'\n",
      " 'Brown Tabby/Black Tabby' 'Tortie/Blue' 'White/Lynx Point'\n",
      " 'Red Tick/Brown Brindle' 'Gold/Gray' 'Silver/White' 'Blue/Cream'\n",
      " 'Blue Tabby/Cream' 'Black Smoke/Blue Tick' 'Tricolor/Cream'\n",
      " 'Gray Tabby/Orange' 'Brown Tabby/Blue' 'Blue Tabby/Buff' 'Tricolor/Red'\n",
      " 'Chocolate/Gold' 'Brown Merle/Brown' 'Cream/Gray' 'Torbie/Calico'\n",
      " 'Yellow/Red' 'Tricolor/Gray' 'White/Silver Tabby' 'Red Tick/Tan'\n",
      " 'Orange/Gray' 'Cream Tabby/Cream Tabby' 'Black Tabby/Black'\n",
      " 'Cream/Tricolor' 'Yellow/Orange Tabby' 'Orange Tabby/Cream'\n",
      " 'Green/Orange' 'Gray/Silver' 'Tricolor/Brown Brindle' 'Black/Tortie'\n",
      " 'White/Lilac Point' 'Black/Brown Merle' 'Blue Tabby/Tan' 'Fawn/Chocolate'\n",
      " 'Gold/Gold' 'White/Silver' 'Blue/Green' 'Blue Merle/Gray'\n",
      " 'Black Smoke/Black' 'Tan/Red Tick' 'Tan/Brown Brindle' 'Orange Tiger'\n",
      " 'Green/Blue' 'Gray/Gray Tabby' 'Blue Cream/Tortie' 'Blue Merle/Cream'\n",
      " 'Silver Lynx Point/White' 'Brown/Pink' 'Tricolor/Chocolate'\n",
      " 'Red Merle/Tricolor' 'Calico/Blue Cream' 'Red Tick/Red'\n",
      " 'Lilac Point/Cream' 'Tan/Apricot' 'Calico/Brown Tabby' 'Blue Smoke/Brown'\n",
      " 'Brown Tabby/Gray Tabby' 'Brown Brindle/Blue Tick' 'Brown/Red Tick'\n",
      " 'Blue Point/Cream' 'Agouti/Gray' 'Blue Smoke/White' 'Agouti/Brown Tabby'\n",
      " 'Blue/Silver' 'Yellow Brindle/Blue' 'Seal Point/Buff'\n",
      " 'Tortie/Black Smoke' 'Torbie/Black' 'Red Merle/Brown Merle' 'Silver/Gray'\n",
      " 'Green/White' 'Brown Brindle/Blue' 'Black Tiger' 'Black/Brown Tabby'\n",
      " 'Sable/Red' 'White/Black Smoke' 'Lynx Point/Tan' 'Black/Gray Tabby'\n",
      " 'Black Smoke/Brown' 'Chocolate/Brown Merle' 'Red/Green' 'Tricolor/Calico'\n",
      " 'Chocolate/Yellow' 'Black Brindle/Blue Tick' 'Gray/Buff'\n",
      " 'Brown/Blue Merle' 'Brown/Blue' 'Black Brindle/Tan' 'Brown/Black Tabby'\n",
      " 'Brown Merle/Black' 'Cream/Red Tick' 'Blue/Yellow' 'Chocolate/Gray'\n",
      " 'Brown Merle/Chocolate' 'White/Brown Tiger' 'Gray/Fawn'\n",
      " 'Red Merle/Red Merle' 'Tricolor/Orange' 'Yellow/Brown' 'Red Tick/Black'\n",
      " 'Red Tick/Brown Merle' 'Silver/Blue' 'Ruddy/Cream' 'Orange/Blue'\n",
      " 'Lynx Point/Gray' 'Fawn/Gray' 'Blue Merle/Brown Brindle'\n",
      " 'Black Smoke/Chocolate' 'Black Tabby/Gray Tabby' 'Blue Tabby/Orange'\n",
      " 'Brown/Brown Merle' 'Tricolor/Tricolor' 'Chocolate/Red Tick'\n",
      " 'Chocolate/Liver Tick' 'Tortie/Brown' 'Silver Tabby/Black'\n",
      " 'Tan/Cream Tabby' 'Tortie Point/Cream' 'Liver/Liver Tick' 'Cream/Cream'\n",
      " 'Brown Brindle/Brown Merle' 'Tan/Brown Merle' 'Blue/Orange' 'Liver/Buff'\n",
      " 'Brown Tabby/Orange Tabby' 'Tricolor/Brown Merle' 'Lynx Point/Cream'\n",
      " 'Torbie/Blue Cream' 'Blue Smoke/Gray' 'White/Black Tiger'\n",
      " 'Lynx Point/Gray Tabby' 'White/Calico Point' 'Brown Tabby/Black Brindle'\n",
      " 'Tricolor/Red Tick' 'Blue/Yellow Brindle' 'Silver/Cream'\n",
      " 'Brown/Black Brindle' 'Brown Brindle/Blue Cream'\n",
      " 'Cream Tabby/Orange Tabby' 'Brown/Apricot' 'Tortie Point/Blue'\n",
      " 'Blue Cream/Buff' 'Tortie/Blue Tabby' 'Sable/Red Merle'\n",
      " 'Black/Seal Point' 'Agouti/Cream' 'Blue Tabby/Blue Cream' 'White/Green'\n",
      " 'Blue Cream/Blue Tabby' 'Brown Brindle/Gray' 'Torbie/Silver Tabby'\n",
      " 'Red Merle/Tan' 'Buff/Yellow' 'Brown Tabby/Lynx Point' 'Black Tabby/Gray'\n",
      " 'Black/Silver Tabby' 'Chocolate/Brown Brindle' 'Red/Brown Brindle'\n",
      " 'Cream Tiger' 'Orange Tabby/Black' 'Brown Brindle/Liver Tick'\n",
      " 'Blue Tabby/Tortie' 'White/Flame Point' 'Tortie Point/Seal Point']\n"
     ]
    }
   ],
   "source": [
    "for c in text_features:\n",
    "    print(c)\n",
    "    print(df[c].unique()) #value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We re-use the helper functions from the 'Text processing' notebook above.\n",
    "\n",
    "__Warning__: cleaning stage can take a few minutes, depending on how much text is there to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text cleaning:  Name\n",
      "Text cleaning:  Found Location\n",
      "Text cleaning:  Breed\n",
      "Text cleaning:  Color\n"
     ]
    }
   ],
   "source": [
    "# Prepare cleaning functions\n",
    "import re, string\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stop_words = [\"a\", \"an\", \"the\", \"this\", \"that\", \"is\", \"it\", \"to\", \"and\"]\n",
    "\n",
    "stemmer = SnowballStemmer('english')\n",
    "\n",
    "def preProcessText(text):\n",
    "    # lowercase and strip leading/trailing white space\n",
    "    text = text.lower().strip()\n",
    "    \n",
    "    # remove HTML tags\n",
    "    text = re.compile('<.*?>').sub('', text)\n",
    "    \n",
    "    # remove punctuation\n",
    "    text = re.compile('[%s]' % re.escape(string.punctuation)).sub(' ', text)\n",
    "    \n",
    "    # remove extra white space\n",
    "    text = re.sub('\\s+', ' ', text)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def lexiconProcess(text, stop_words, stemmer):\n",
    "    filtered_sentence = []\n",
    "    words = text.split(\" \")\n",
    "    for w in words:\n",
    "        if w not in stop_words:\n",
    "            filtered_sentence.append(stemmer.stem(w))\n",
    "    text = \" \".join(filtered_sentence)\n",
    "    \n",
    "    return text\n",
    "\n",
    "def cleanSentence(text, stop_words, stemmer):\n",
    "    return lexiconProcess(preProcessText(text), stop_words, stemmer)\n",
    "\n",
    "# Clean the text features\n",
    "for c in text_features:\n",
    "    print('Text cleaning: ', c)\n",
    "    df[c] = [cleanSentence(item, stop_words, stemmer) for item in df[c].values]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cleaned text features are ready to be vectorized after the train/test split."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note__: more exploratory data analysis might reveal other important hidden atributes and/or relationships of the model features considered. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. <a name=\"4\">Training and test datasets</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "We split our dataset into training (90%) and test (10%) subsets using sklearn's [__train_test_split()__](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(df, test_size=0.1, shuffle=True, random_state=23)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Target balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (85936, 13)\n",
      "Class 0 samples in the training set: 37499\n",
      "Class 1 samples in the training set: 48437\n",
      "Class 0 samples in the test set: 4132\n",
      "Class 1 samples in the test set: 5417\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape:', train_data.shape)\n",
    "\n",
    "print('Class 0 samples in the training set:', sum(train_data[model_target] == 0))\n",
    "print('Class 1 samples in the training set:', sum(train_data[model_target] == 1))\n",
    "\n",
    "print('Class 0 samples in the test set:', sum(test_data[model_target] == 0))\n",
    "print('Class 1 samples in the test set:', sum(test_data[model_target] == 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important note:__ We want to fix the imbalance only in training set. We shouldn't change the validation and test sets, as these should follow the original distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import shuffle\n",
    "\n",
    "class_0_no = train_data[train_data[model_target] == 0]\n",
    "class_1_no = train_data[train_data[model_target] == 1]\n",
    "\n",
    "upsampled_class_0_no = class_0_no.sample(n=len(class_1_no), replace=True, random_state=42)\n",
    "\n",
    "train_data = pd.concat([class_1_no, upsampled_class_0_no])\n",
    "train_data = shuffle(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (96874, 13)\n",
      "Class 1 samples in the training set: 48437\n",
      "Class 0 samples in the training set: 48437\n"
     ]
    }
   ],
   "source": [
    "print('Training set shape:', train_data.shape)\n",
    "\n",
    "print('Class 1 samples in the training set:', sum(train_data[model_target] == 1))\n",
    "print('Class 0 samples in the training set:', sum(train_data[model_target] == 0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. <a name=\"5\">Data processing with Pipeline and ColumnTransformer</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's build a more complex pipeline today. We first build separate pipelines to handle the numerical, categorical, and text features, and then combine them into a composite pipeline along with an estimator, a [Decision Tree Classifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html) here.\n",
    "\n",
    "   * For the numerical features pipeline, the __numerical_processor__ below, we impute missing values with the mean using sklearn's SimpleImputer, followed by a MinMaxScaler (don't have to scale features when using Decision Trees, but it's a good idea to see how to use more data transforms). If different processing is desired for different numerical features, different pipelines should be built - just like shown below for the two text features.\n",
    "   \n",
    "   \n",
    "   * In the categoricals pipeline, the __categorical_processor__ below, we impute with a placeholder value (no effect here as we already encoded the 'nan's), and encode with sklearn's OneHotEncoder. If computing memory is an issue, it is a good idea to check categoricals' unique values, to get an estimate of many dummy features will be created by one-hot encoding. Note the __handle_unknown__ parameter that tells the encoder to ignore (rather than throw an error for) any unique value that might show in the validation/and or test set that was not present in the initial training set.\n",
    "  \n",
    "   \n",
    "   * And, finally, also with memory usage in mind, we build two more pipelines, one for each of our text features, trying different vocabulary sizes.\n",
    "   \n",
    "The selective preparations of the dataset features are then put together into a collective __ColumnTransformer__, to be finally used in a __Pipeline__ along with an estimator. This ensures that the transforms are performed automatically on the raw data when fitting the model and when making predictions, such as when evaluating the model on a validation dataset via cross-validation or making predictions on a test dataset in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>div.sk-top-container {color: black;background-color: white;}div.sk-toggleable {background-color: white;}label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.2em 0.3em;box-sizing: border-box;text-align: center;}div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}div.sk-estimator {font-family: monospace;background-color: #f0f8ff;margin: 0.25em 0.25em;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;}div.sk-estimator:hover {background-color: #d4ebff;}div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 2em;bottom: 0;left: 50%;}div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;}div.sk-item {z-index: 1;}div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;}div.sk-parallel-item {display: flex;flex-direction: column;position: relative;background-color: white;}div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}div.sk-parallel-item:only-child::after {width: 0;}div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0.2em;box-sizing: border-box;padding-bottom: 0.1em;background-color: white;position: relative;}div.sk-label label {font-family: monospace;font-weight: bold;background-color: white;display: inline-block;line-height: 1.2em;}div.sk-label-container {position: relative;z-index: 2;text-align: center;}div.sk-container {display: inline-block;position: relative;}</style><div class=\"sk-top-container\"><div class=\"sk-container\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"d3872a9d-2929-4e52-af96-93d3e98b98ca\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"d3872a9d-2929-4e52-af96-93d3e98b98ca\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[('data_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                                  Pipeline(steps=[('num_imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('num_scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['Age upon Intake Days',\n",
       "                                                   'Age upon Outcome Days']),\n",
       "                                                 ('categorical_pre',\n",
       "                                                  Pipeline(steps=[('cat_imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('cat_encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Sex upon Outcome',\n",
       "                                                   'Intake Type',\n",
       "                                                   'Intake Condition',\n",
       "                                                   'Pet Type',\n",
       "                                                   'Sex upon Intake']),\n",
       "                                                 ('text_pre_0',\n",
       "                                                  Pipeline(steps=[('text_vect_0',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'Name'),\n",
       "                                                 ('text_pre_1',\n",
       "                                                  Pipeline(steps=[('text_vect_1',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=150))]),\n",
       "                                                  'Found Location')])),\n",
       "                ('dt', DecisionTreeClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"10de25eb-9059-422f-8e44-88c17ed803dc\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"10de25eb-9059-422f-8e44-88c17ed803dc\">data_preprocessing: ColumnTransformer</label><div class=\"sk-toggleable__content\"><pre>ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                 Pipeline(steps=[('num_imputer',\n",
       "                                                  SimpleImputer()),\n",
       "                                                 ('num_scaler',\n",
       "                                                  MinMaxScaler())]),\n",
       "                                 ['Age upon Intake Days',\n",
       "                                  'Age upon Outcome Days']),\n",
       "                                ('categorical_pre',\n",
       "                                 Pipeline(steps=[('cat_imputer',\n",
       "                                                  SimpleImputer(fill_value='missing',\n",
       "                                                                strategy='constant')),\n",
       "                                                 ('cat_encoder',\n",
       "                                                  OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                 ['Sex upon Outcome', 'Intake Type',\n",
       "                                  'Intake Condition', 'Pet Type',\n",
       "                                  'Sex upon Intake']),\n",
       "                                ('text_pre_0',\n",
       "                                 Pipeline(steps=[('text_vect_0',\n",
       "                                                  CountVectorizer(binary=True,\n",
       "                                                                  max_features=50))]),\n",
       "                                 'Name'),\n",
       "                                ('text_pre_1',\n",
       "                                 Pipeline(steps=[('text_vect_1',\n",
       "                                                  CountVectorizer(binary=True,\n",
       "                                                                  max_features=150))]),\n",
       "                                 'Found Location')])</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"993ca65f-0aae-49f9-ad7d-ad2095e0779b\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"993ca65f-0aae-49f9-ad7d-ad2095e0779b\">numerical_pre</label><div class=\"sk-toggleable__content\"><pre>['Age upon Intake Days', 'Age upon Outcome Days']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"685d59c1-dfbb-4b41-a9c9-1eeb7d72d709\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"685d59c1-dfbb-4b41-a9c9-1eeb7d72d709\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8afb23b6-01c7-45fe-9436-ae2ba9277f8d\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8afb23b6-01c7-45fe-9436-ae2ba9277f8d\">MinMaxScaler</label><div class=\"sk-toggleable__content\"><pre>MinMaxScaler()</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"3442cd6a-9fcd-4176-a289-0589a6b7fda9\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"3442cd6a-9fcd-4176-a289-0589a6b7fda9\">categorical_pre</label><div class=\"sk-toggleable__content\"><pre>['Sex upon Outcome', 'Intake Type', 'Intake Condition', 'Pet Type', 'Sex upon Intake']</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"90146894-b9f4-4830-9000-4bfe4aadb6f7\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"90146894-b9f4-4830-9000-4bfe4aadb6f7\">SimpleImputer</label><div class=\"sk-toggleable__content\"><pre>SimpleImputer(fill_value='missing', strategy='constant')</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"c1a26dab-d82e-47f3-957d-35c5fae859b2\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"c1a26dab-d82e-47f3-957d-35c5fae859b2\">OneHotEncoder</label><div class=\"sk-toggleable__content\"><pre>OneHotEncoder(handle_unknown='ignore')</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0beee74f-f9ea-42f9-b870-b09a66eea464\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0beee74f-f9ea-42f9-b870-b09a66eea464\">text_pre_0</label><div class=\"sk-toggleable__content\"><pre>Name</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"ce906d52-bc11-4bad-901e-40e44afddd06\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"ce906d52-bc11-4bad-901e-40e44afddd06\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, max_features=50)</pre></div></div></div></div></div></div></div></div><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"8a2718ce-6377-4954-9696-c74fdc10dc36\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"8a2718ce-6377-4954-9696-c74fdc10dc36\">text_pre_1</label><div class=\"sk-toggleable__content\"><pre>Found Location</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"5b312afe-c8f4-434d-bd16-83b91e0ff9b0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"5b312afe-c8f4-434d-bd16-83b91e0ff9b0\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer(binary=True, max_features=150)</pre></div></div></div></div></div></div></div></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"0ef72b19-74b3-4d94-b897-59825857aea0\" type=\"checkbox\" ><label class=\"sk-toggleable__label\" for=\"0ef72b19-74b3-4d94-b897-59825857aea0\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('data_preprocessing',\n",
       "                 ColumnTransformer(transformers=[('numerical_pre',\n",
       "                                                  Pipeline(steps=[('num_imputer',\n",
       "                                                                   SimpleImputer()),\n",
       "                                                                  ('num_scaler',\n",
       "                                                                   MinMaxScaler())]),\n",
       "                                                  ['Age upon Intake Days',\n",
       "                                                   'Age upon Outcome Days']),\n",
       "                                                 ('categorical_pre',\n",
       "                                                  Pipeline(steps=[('cat_imputer',\n",
       "                                                                   SimpleImputer(fill_value='missing',\n",
       "                                                                                 strategy='constant')),\n",
       "                                                                  ('cat_encoder',\n",
       "                                                                   OneHotEncoder(handle_unknown='ignore'))]),\n",
       "                                                  ['Sex upon Outcome',\n",
       "                                                   'Intake Type',\n",
       "                                                   'Intake Condition',\n",
       "                                                   'Pet Type',\n",
       "                                                   'Sex upon Intake']),\n",
       "                                                 ('text_pre_0',\n",
       "                                                  Pipeline(steps=[('text_vect_0',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=50))]),\n",
       "                                                  'Name'),\n",
       "                                                 ('text_pre_1',\n",
       "                                                  Pipeline(steps=[('text_vect_1',\n",
       "                                                                   CountVectorizer(binary=True,\n",
       "                                                                                   max_features=150))]),\n",
       "                                                  'Found Location')])),\n",
       "                ('dt', DecisionTreeClassifier())])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "### COLUMN_TRANSFORMER ###\n",
    "##########################\n",
    "\n",
    "# Preprocess the numerical features\n",
    "numerical_processor = Pipeline([\n",
    "    ('num_imputer', SimpleImputer(strategy='mean')),\n",
    "    ('num_scaler', MinMaxScaler()) # Shown in case is needed, not a must with Decision Trees\n",
    "                                ])\n",
    "                  \n",
    "# Preprocess the categorical features\n",
    "categorical_processor = Pipeline([\n",
    "    ('cat_imputer', SimpleImputer(strategy='constant', fill_value='missing')), # Shown in case is needed, no effect here as we already imputed with 'nan' strings\n",
    "    ('cat_encoder', OneHotEncoder(handle_unknown='ignore')) # handle_unknown tells it to ignore (rather than throw an error for) any value that was not present in the initial training set.\n",
    "                                ])\n",
    "\n",
    "# Preprocess 1st text feature\n",
    "text_processor_0 = Pipeline([\n",
    "    ('text_vect_0', CountVectorizer(binary=True, max_features=50))\n",
    "                                ])\n",
    "\n",
    "# Preprocess 2nd text feature (larger vocabulary)\n",
    "text_precessor_1 = Pipeline([\n",
    "    ('text_vect_1', CountVectorizer(binary=True, max_features=150))\n",
    "                                ])\n",
    "\n",
    "# Combine all data preprocessors from above (add more, if you choose to define more!)\n",
    "# For each processor/step specify: a name, the actual process, and finally the features to be processed\n",
    "data_preprocessor = ColumnTransformer([\n",
    "    ('numerical_pre', numerical_processor, numerical_features),\n",
    "    ('categorical_pre', categorical_processor, categorical_features),\n",
    "    ('text_pre_0', text_processor_0, text_features[0]),\n",
    "    ('text_pre_1', text_precessor_1, text_features[1])\n",
    "                                    ]) \n",
    "\n",
    "### PIPELINE ###\n",
    "################\n",
    "\n",
    "# Pipeline desired all data transformers, along with an estimator at the end\n",
    "# Later you can set/reach the parameters using the names issued - for hyperparameter tuning, for example\n",
    "pipeline = Pipeline([\n",
    "    ('data_preprocessing', data_preprocessor),\n",
    "    ('dt', DecisionTreeClassifier())\n",
    "                    ])\n",
    "\n",
    "# Visualize the pipeline\n",
    "# This will come in handy especially when building more complex pipelines, stringing together multiple preprocessing steps\n",
    "from sklearn import set_config\n",
    "set_config(display='diagram')\n",
    "pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. <a name=\"6\">Train a classifier</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Let's first train and test the above composite pipeline on the train and the test sets.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[45605  2832]\n",
      " [ 1996 46441]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      0.94      0.95     48437\n",
      "         1.0       0.94      0.96      0.95     48437\n",
      "\n",
      "    accuracy                           0.95     96874\n",
      "   macro avg       0.95      0.95      0.95     96874\n",
      "weighted avg       0.95      0.95      0.95     96874\n",
      "\n",
      "Accuracy (training): 0.9501620661890703\n",
      "[[3166  966]\n",
      " [ 866 4551]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.79      0.77      0.78      4132\n",
      "         1.0       0.82      0.84      0.83      5417\n",
      "\n",
      "    accuracy                           0.81      9549\n",
      "   macro avg       0.81      0.80      0.80      9549\n",
      "weighted avg       0.81      0.81      0.81      9549\n",
      "\n",
      "Accuracy (test): 0.8081474499947638\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Get train data to train the pipeline\n",
    "X_train = train_data[model_features]\n",
    "y_train = train_data[model_target]\n",
    "\n",
    "# Fit the Pipeline to training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Use the fitted pipeline to make predictions on the train dataset\n",
    "train_predictions = pipeline.predict(X_train)\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Accuracy (training):\", accuracy_score(y_train, train_predictions))\n",
    "\n",
    "# Get test data to test the pipeline\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted pipeline to make predictions on the test dataset\n",
    "test_predictions = pipeline.predict(X_test)\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"Accuracy (test):\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. <a name=\"7\">Test the classifier</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "Now we test the best model with the best parameters on \"unseen\" data (our test data).\n",
    "\n",
    "Before that, let's first see how the model works on the training dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the train set:\n",
      "[[39565  8872]\n",
      " [ 4506 43931]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.82      0.86     48437\n",
      "         1.0       0.83      0.91      0.87     48437\n",
      "\n",
      "    accuracy                           0.86     96874\n",
      "   macro avg       0.86      0.86      0.86     96874\n",
      "weighted avg       0.86      0.86      0.86     96874\n",
      "\n",
      "Train accuracy: 0.8619030906125482\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Use the fitted model to make predictions on the train dataset\n",
    "train_predictions = classifier.predict(X_train)\n",
    "\n",
    "print('Model performance on the train set:')\n",
    "print(confusion_matrix(y_train, train_predictions))\n",
    "print(classification_report(y_train, train_predictions))\n",
    "print(\"Train accuracy:\", accuracy_score(y_train, train_predictions))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, let's evaluate the performance of the classifier on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model performance on the test set:\n",
      "[[3222  910]\n",
      " [ 621 4796]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.84      0.78      0.81      4132\n",
      "         1.0       0.84      0.89      0.86      5417\n",
      "\n",
      "    accuracy                           0.84      9549\n",
      "   macro avg       0.84      0.83      0.84      9549\n",
      "weighted avg       0.84      0.84      0.84      9549\n",
      "\n",
      "Test accuracy: 0.8396690752958424\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "# Get test data to test the classifier\n",
    "X_test = test_data[model_features]\n",
    "y_test = test_data[model_target]\n",
    "\n",
    "# Use the fitted model to make predictions on the test dataset\n",
    "# Test data going through the Pipeline it's first imputed (with means from the train), scaled (with the min/max from the train data), and finally used to make predictions\n",
    "test_predictions = classifier.predict(X_test)\n",
    "\n",
    "print('Model performance on the test set:')\n",
    "print(confusion_matrix(y_test, test_predictions))\n",
    "print(classification_report(y_test, test_predictions))\n",
    "print(\"Test accuracy:\", accuracy_score(y_test, test_predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. <a name=\"28\">Improvement Ideas</a>\n",
    "(<a href=\"#0\">Go to top</a>)\n",
    "\n",
    "* Try target enconding for categorical variables. (check slides)\n",
    "* Feature selection: Not all features may be important, we can achieve higher performance by selecting a subset of our features."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
